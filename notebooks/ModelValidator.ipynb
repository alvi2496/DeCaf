{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelValidator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue-brQOCOR4A",
        "colab_type": "text"
      },
      "source": [
        "# Notebook for the experiment of building **DeCaf** (**De**sign **C**l**a**ssi**f**ier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_wliyuuasNx",
        "colab_type": "text"
      },
      "source": [
        "## Architectural Overview/Design\n",
        "In Progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up9iaDnZM9l",
        "colab_type": "text"
      },
      "source": [
        "## Objective\n",
        "The main objective is to validate the model with various test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A-ie768Gp-2",
        "colab_type": "code",
        "outputId": "f29e69b6-cac2-454b-b4f4-d65cfec1ec40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKsVKbYpOjpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All the imports\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "from joblib import load\n",
        "from datetime import datetime as dt\n",
        "from prettytable import PrettyTable\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZJA1VBBRD2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Control Parameters\n",
        "dm_test_validation = False\n",
        "dm_cross_validation = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8H39Gum_Jy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log(log_file_path, message):\n",
        "  file = pd.DataFrame([[str(dt.now()), 'info', message]], columns=['timestamp', 'type', 'message'])\n",
        "  if not os.path.exists(log_file_path):\n",
        "    file.to_csv(log_file_path)\n",
        "  else:\n",
        "    file.to_csv(log_file_path, mode='a', header=False)\n",
        "\n",
        "def log_result(log_file_path, message):\n",
        "  f = open(log_file_path, \"a\")\n",
        "  f.write(str(dt.now()))\n",
        "  f.write(message)\n",
        "  f.close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLxh9uyZN4Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auc_score(X, Y, model, process_number, auc):\n",
        "  pred = model.predict(X)\n",
        "  auc[process_number] = metrics.roc_auc_score(Y, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQKN9WbuOIus",
        "colab_type": "text"
      },
      "source": [
        "## Load the data mining models and calculate the **ROC AUC** score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n01kigvy_IIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model_paths = [\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/knn.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/dt.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/rf.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/lr.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/gnb.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/nn.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/ab.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/qda.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/lsvm.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/rbf_svm.joblib\"\n",
        "  ]\n",
        "  classifier_names = [\n",
        "      \"Nearest Neighbors\",\n",
        "      \"Decision Tree\",\n",
        "      \"Random Forest\",\n",
        "      \"Logistic Regression\",\n",
        "      \"Gaussian Naive Bayes\", \n",
        "      \"Neural Net\", \n",
        "      \"AdaBoost\",\n",
        "      \"QDA\",    \n",
        "      \"Linear SVM\", \n",
        "      \"RBF SVM\",\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7GNT8gWU_fE6",
        "colab": {}
      },
      "source": [
        "def validate_dm_models(test_data_names, test_data, test_labels, logs):\n",
        "\n",
        "  table = PrettyTable()\n",
        "  table.field_names = ['Dataset'] + classifier_names\n",
        "  performance_log = []\n",
        "  logs.append(\"Validated at: \" + str(dt.now()))\n",
        "  for i, data in enumerate(test_data):\n",
        "    aucs = []\n",
        "    print(str(dt.now()) + \" Creating process for: \", test_data_names[i])\n",
        "    # logs.append(str(dt.now()) + \" Creating process for: \" + test_data_names[i])\n",
        "    manager = mp.Manager()\n",
        "    auc = manager.dict()\n",
        "    jobs = []\n",
        "    for index, model_path in enumerate(model_paths):\n",
        "      model = load(model_path)\n",
        "      print(str(dt.now()) + \" Validating from: \", classifier_names[index])\n",
        "      # logs.append(str(dt.now()) + \" Validating from: \" + classifier_names[index])\n",
        "      p = mp.Process(target=auc_score, args=(test_data[i], \\\n",
        "                                             test_labels[i], model, index, auc))\n",
        "      jobs.append(p)\n",
        "      p.start()\n",
        "    \n",
        "    for proc in jobs:\n",
        "      proc.join()\n",
        "    \n",
        "    for index, name in enumerate(classifier_names):\n",
        "      aucs.append(round(auc[index], 4))\n",
        "\n",
        "    table.add_row([test_data_names[i]] + aucs)\n",
        "  \n",
        "  print(table)\n",
        "  logs.append(table.get_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljPxEs-4Ngx0",
        "colab_type": "text"
      },
      "source": [
        "## Validate the models\n",
        "- We use Area Under the Receiver Operating Characteristic Curve (**ROC AUC**) from prediction scores as the validation criteria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEj1rF_93pRq",
        "colab_type": "text"
      },
      "source": [
        "### Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_qzpOVv3onz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_T = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/X_T.npy\")\n",
        "Y_T = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/Y_T.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjv-_GPbW9Fn",
        "colab_type": "text"
      },
      "source": [
        "### Validate the trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87RQYCk9eNJU",
        "colab_type": "code",
        "outputId": "47e39c18-cf87-471f-eb2f-242e5a42fc81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "result_path = \"/content/drive/My Drive/documents/projects/DeCaf/results/test_data.txt\"\n",
        "\n",
        "if os.path.exists(result_path) and not dm_test_validation:\n",
        "  with open(result_path, \"r\") as f:\n",
        "    print(f.read())\n",
        "else:\n",
        "  logs = []\n",
        "  test_data_names = [\"SO test data\"]\n",
        "  test_data = [X_T]\n",
        "  test_labels = [Y_T]\n",
        "  validate_dm_models(test_data_names, test_data, test_labels, logs)\n",
        "  with open(result_path, \"a+\") as f:\n",
        "    f.write(\"\\n\".join(logs) + \"\\n\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 03:13:30.517857 Creating process for: SO test data\n",
            "2020-04-07 03:13:35.993498 Validating from: Nearest Neighbors\n",
            "2020-04-07 03:13:36.050743 Validating from: Decision Tree\n",
            "2020-04-07 03:13:38.297640 Validating from: Random Forest\n",
            "2020-04-07 03:13:38.702103 Validating from: Logistic Regression\n",
            "2020-04-07 03:13:38.728904 Validating from: Gaussian Naive Bayes\n",
            "2020-04-07 03:13:39.422491 Validating from: Neural Net\n",
            "2020-04-07 03:13:40.053497 Validating from: AdaBoost\n",
            "2020-04-07 03:13:40.826526 Validating from: QDA\n",
            "2020-04-07 03:13:45.228753 Validating from: Linear SVM\n",
            "2020-04-07 03:13:48.762703 Validating from: RBF SVM\n",
            "+--------------+-------------------+---------------+---------------+---------------------+----------------------+------------+----------+--------+------------+---------+\n",
            "|   Dataset    | Nearest Neighbors | Decision Tree | Random Forest | Logistic Regression | Gaussian Naive Bayes | Neural Net | AdaBoost |  QDA   | Linear SVM | RBF SVM |\n",
            "+--------------+-------------------+---------------+---------------+---------------------+----------------------+------------+----------+--------+------------+---------+\n",
            "| SO test data |       0.7922      |     0.7266    |     0.8236    |        0.8298       |        0.7816        |   0.8437   |  0.7962  | 0.8016 |   0.8117   |  0.8468 |\n",
            "+--------------+-------------------+---------------+---------------+---------------------+----------------------+------------+----------+--------+------------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLFv8r8enaY-",
        "colab_type": "text"
      },
      "source": [
        "## Cross dataset validation of the models\n",
        "We are taking the following datasets to validate the models:\n",
        "- Brunet 2014 (brunet2014.csv)\n",
        "- Shakiba 2016 (shakiba2016.csv)\n",
        "- Viviani 2018 (viviani2018.csv)\n",
        "- Self Admitted Technical Debt/ SATD (satd.csv)\n",
        "- Stack Overflow (so.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GruohJ5b1rbc",
        "colab": {}
      },
      "source": [
        "cross_dataset_names = [\"Brunet 2014\", \n",
        "                       \"Shakiba 2016\", \"Viviani 2018\",\n",
        "                       \"SATD\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L24EjgKXpJY1",
        "colab_type": "text"
      },
      "source": [
        "### Load the data Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCM9TJfzpZeq",
        "colab_type": "code",
        "outputId": "f08848d0-e5f2-429f-aace-14ff63a1d3d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_brunet2014 = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_brunet2014.npy\")\n",
        "Y_brunet2014 = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_brunet2014.npy\")\n",
        "print(X_brunet2014.shape)\n",
        "print(Y_brunet2014.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159, 200)\n",
            "(159,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXLiNFapsIbQ",
        "colab_type": "code",
        "outputId": "82c026c1-27b4-41bb-dd14-8cef3a9fd472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_shakiba2016 = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_shakiba2016.npy\")\n",
        "Y_shakiba2016 = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_shakiba2016.npy\")\n",
        "print(X_shakiba2016.shape)\n",
        "print(Y_shakiba2016.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67, 200)\n",
            "(67,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKuvSBTGsJG8",
        "colab_type": "code",
        "outputId": "ecdf042e-d24d-4681-9b7f-061c2ca63694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_viviani2018 = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_viviani2018.npy\")\n",
        "Y_viviani2018 = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_viviani2018.npy\")\n",
        "print(X_viviani2018.shape)\n",
        "print(Y_viviani2018.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1969, 200)\n",
            "(1969,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJvSgex_sJgs",
        "colab_type": "code",
        "outputId": "e00f160b-ff5a-4181-eb11-0c44d13ad63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_satd = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_satd.npy\")\n",
        "Y_satd = np.load(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_satd.npy\")\n",
        "print(X_satd.shape)\n",
        "print(Y_satd.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2609, 200)\n",
            "(2609,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgaq6VXPsJ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_so = \n",
        "# Y_so = \n",
        "# print(X_so.shape)\n",
        "# print(Y_so.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsuSsmFCtf2J",
        "colab_type": "text"
      },
      "source": [
        "### Validate with the Trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aWuwFIZtlLj",
        "colab_type": "code",
        "outputId": "543ec99d-b20e-4835-f1e7-e0b5a3b8af81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "source": [
        "result_path = \"/content/drive/My Drive/documents/projects/DeCaf/results/cross_data.txt\"\n",
        "\n",
        "if os.path.exists(result_path) and not dm_cross_validation:\n",
        "  with open(result_path, \"r\") as f:\n",
        "    print(f.read())\n",
        "else:\n",
        "  logs = []\n",
        "  test_data_names = [\"SO test data\"]\n",
        "  test_data = [X_brunet2014, \n",
        "             X_shakiba2016, X_viviani2018, X_satd]\n",
        "  test_labels = [Y_brunet2014, \n",
        "                Y_shakiba2016, Y_viviani2018, Y_satd]\n",
        "  validate_dm_models(cross_dataset_names, test_data, test_labels, logs)\n",
        "  with open(result_path, \"a+\") as f:\n",
        "    f.write(\"\\n\".join(logs) + \"\\n\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 17:56:56.396232 Creating process for: Brunet 2014\n",
            "2020-04-07 17:57:05.542378 Validating from: Nearest Neighbors\n",
            "2020-04-07 17:57:06.291415 Validating from: Decision Tree\n",
            "2020-04-07 17:57:10.585382 Validating from: Random Forest\n",
            "2020-04-07 17:57:11.413486 Validating from: Logistic Regression\n",
            "2020-04-07 17:57:12.264672 Validating from: Gaussian Naive Bayes\n",
            "2020-04-07 17:57:13.153127 Validating from: Neural Net\n",
            "2020-04-07 17:57:13.843486 Validating from: AdaBoost\n",
            "2020-04-07 17:57:14.550347 Validating from: QDA\n",
            "2020-04-07 17:57:18.726873 Validating from: Linear SVM\n",
            "2020-04-07 17:57:22.198352 Validating from: RBF SVM\n",
            "2020-04-07 17:57:28.306336 Creating process for: Shakiba 2016\n",
            "2020-04-07 17:57:29.943071 Validating from: Nearest Neighbors\n",
            "2020-04-07 17:57:29.990966 Validating from: Decision Tree\n",
            "2020-04-07 17:57:32.028523 Validating from: Random Forest\n",
            "2020-04-07 17:57:32.505713 Validating from: Logistic Regression\n",
            "2020-04-07 17:57:32.533431 Validating from: Gaussian Naive Bayes\n",
            "2020-04-07 17:57:32.599528 Validating from: Neural Net\n",
            "2020-04-07 17:57:32.685306 Validating from: AdaBoost\n",
            "2020-04-07 17:57:32.727554 Validating from: QDA\n",
            "2020-04-07 17:57:33.856668 Validating from: Linear SVM\n",
            "2020-04-07 17:57:34.485739 Validating from: RBF SVM\n",
            "2020-04-07 17:57:38.192790 Creating process for: Viviani 2018\n",
            "2020-04-07 17:57:39.751054 Validating from: Nearest Neighbors\n",
            "2020-04-07 17:57:39.799087 Validating from: Decision Tree\n",
            "2020-04-07 17:57:40.804832 Validating from: Random Forest\n",
            "2020-04-07 17:57:41.115462 Validating from: Logistic Regression\n",
            "2020-04-07 17:57:41.143423 Validating from: Gaussian Naive Bayes\n",
            "2020-04-07 17:57:41.219125 Validating from: Neural Net\n",
            "2020-04-07 17:57:41.290371 Validating from: AdaBoost\n",
            "2020-04-07 17:57:41.356792 Validating from: QDA\n",
            "2020-04-07 17:57:42.384994 Validating from: Linear SVM\n",
            "2020-04-07 17:57:43.176482 Validating from: RBF SVM\n",
            "2020-04-07 18:00:41.171529 Creating process for: SATD\n",
            "2020-04-07 18:00:42.869661 Validating from: Nearest Neighbors\n",
            "2020-04-07 18:00:42.942862 Validating from: Decision Tree\n",
            "2020-04-07 18:00:44.563802 Validating from: Random Forest\n",
            "2020-04-07 18:00:44.898824 Validating from: Logistic Regression\n",
            "2020-04-07 18:00:44.922558 Validating from: Gaussian Naive Bayes\n",
            "2020-04-07 18:00:44.988868 Validating from: Neural Net\n",
            "2020-04-07 18:00:45.115841 Validating from: AdaBoost\n",
            "2020-04-07 18:00:45.186774 Validating from: QDA\n",
            "2020-04-07 18:00:46.323135 Validating from: Linear SVM\n",
            "2020-04-07 18:00:47.038892 Validating from: RBF SVM\n",
            "+--------------+-------------------+---------------+---------------+---------------------+----------------------+------------+----------+-----+------------+---------+\n",
            "|   Dataset    | Nearest Neighbors | Decision Tree | Random Forest | Logistic Regression | Gaussian Naive Bayes | Neural Net | AdaBoost | QDA | Linear SVM | RBF SVM |\n",
            "+--------------+-------------------+---------------+---------------+---------------------+----------------------+------------+----------+-----+------------+---------+\n",
            "| Brunet 2014  |       0.4982      |     0.4752    |     0.5195    |         0.5         |         0.5          |   0.5328   |  0.5144  | 0.5 |    0.5     |   0.5   |\n",
            "| Shakiba 2016 |       0.5481      |     0.4252    |      0.5      |         0.5         |         0.5          |   0.5081   |  0.5324  | 0.5 |    0.5     |   0.5   |\n",
            "| Viviani 2018 |       0.4994      |     0.4978    |     0.4969    |         0.5         |         0.5          |   0.5033   |  0.4973  | 0.5 |    0.5     |   0.5   |\n",
            "|     SATD     |       0.5051      |     0.4981    |     0.4946    |         0.5         |         0.5          |   0.4899   |   0.5    | 0.5 |    0.5     |   0.5   |\n",
            "+--------------+-------------------+---------------+---------------+---------------------+----------------------+------------+----------+-----+------------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}