{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbedder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmL3BR/iY1btZOwm4k9Twd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm-b0RB9AC7r",
        "colab_type": "text"
      },
      "source": [
        "## Architectural Overview/Design\n",
        "![alt text](https://raw.githubusercontent.com/alvi2496/DeCaf/master/assets/word_embedding.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up9iaDnZM9l",
        "colab_type": "text"
      },
      "source": [
        "## Objective\n",
        "The main objective is to classify discussions from pull request, issue tracker commit messages and code comments as `design` or `general`. We also want to make the classifier cross project compatible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Av-qUhZOah",
        "colab_type": "text"
      },
      "source": [
        "## Data Collection\n",
        "- We intent to have three types of data. One data is to train the `Word Embedding` model. As `Word Embedding` requires structured form of literature, we have used sentences from literatures(ex. papers and books). Also we have restricted our choice of papers and books to only from the Software Engineering domain for keep the context of our `Word Embedding` model restricted to Software Engineering. Our `Word Embedding` model will be used to vectorize our train data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kJqfFkNeAWNU"
      },
      "source": [
        "## Data Cleaning\n",
        "Raw data can have a lot of noise. Specially when scraped from documents of website, it can contain a lot of misinformation in the form of names, punctuations, numbers(ex. years), misspelled and incompleted words. Also it can have a lot of stopwords that can make the model confused. We have removed all this to make our data as clean as possible. After the cleaning process, out data only contains words that are not stopwords, present in the english dictionary and has lenght greater than three."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A-ie768Gp-2",
        "colab_type": "code",
        "outputId": "850aabd6-3278-40df-e8ea-2777d8637543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOd6VG5aIqdf",
        "colab_type": "text"
      },
      "source": [
        "## Assign Data location\n",
        "- literature: holds the data for word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9gkg8dEI5fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "literature_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/literature.txt\"\n",
        "enhanced_literature_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/enhanced_literature.txt\"\n",
        "so_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/pre_trained/so.bin\"\n",
        "we_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/we.bin\"\n",
        "enhanced_we_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/enhanced_we.bin\"\n",
        "enhanced_we_model_file_300d = \"/content/drive/My Drive/documents/projects/DeCaf/models/enhanced_we_300d.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa6lcx4ePsEM",
        "colab_type": "text"
      },
      "source": [
        "## Enhance the Literature\n",
        "- We enhance the `literature` using pre-trained model `so.bin`\n",
        "  - We are taking every word of literature\n",
        "  - Inject additional similar word related to software engineering to enhance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF2d3MNeblyF",
        "colab_type": "text"
      },
      "source": [
        "### Read the literature.txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLcD_v0AbpX_",
        "colab_type": "code",
        "outputId": "380eb9c5-fe57-4086-ec1a-611ae91ee842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "literature = open(literature_file, 'r')\n",
        "words = literature.read().split(\" \")\n",
        "literature.close()\n",
        "print(\"Total words in literature: \", len(words)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words in literature:  1575439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FzeUGXLEg-K",
        "colab_type": "text"
      },
      "source": [
        "### Divide the words in chunks\n",
        "- We divide the words in chunks to implement multiprocessing on each chunks\n",
        "- We take 300000 words in each chunks leading to 5 chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Hx6AT9E7XR",
        "colab_type": "code",
        "outputId": "e5432d48-ee46-493d-9f3e-a42f0e678cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "file_chunks = []\n",
        "file_chunks_names = []\n",
        "index = 0\n",
        "while index < len(words) - 1:\n",
        "  chunk = []\n",
        "  lower_limit = index\n",
        "  i = 0\n",
        "  while i < 4 and lower_limit < len(words) - 1:\n",
        "    upper_limit = lower_limit + 75000\n",
        "    if upper_limit > len(words):\n",
        "      upper_limit = len(words) - 1\n",
        "    chunk.append(words[lower_limit:upper_limit])\n",
        "    print(\"lower_limit: \" + str(lower_limit) + \" upper_limit: \" + str(upper_limit))\n",
        "    lower_limit = upper_limit\n",
        "    i = i + 1\n",
        "  file_chunks_names.append(str(index) + '_' + str(lower_limit))\n",
        "  index = lower_limit\n",
        "  file_chunks.append(chunk)\n",
        "print(file_chunks_names)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lower_limit: 0 upper_limit: 75000\n",
            "lower_limit: 75000 upper_limit: 150000\n",
            "lower_limit: 150000 upper_limit: 225000\n",
            "lower_limit: 225000 upper_limit: 300000\n",
            "lower_limit: 300000 upper_limit: 375000\n",
            "lower_limit: 375000 upper_limit: 450000\n",
            "lower_limit: 450000 upper_limit: 525000\n",
            "lower_limit: 525000 upper_limit: 600000\n",
            "lower_limit: 600000 upper_limit: 675000\n",
            "lower_limit: 675000 upper_limit: 750000\n",
            "lower_limit: 750000 upper_limit: 825000\n",
            "lower_limit: 825000 upper_limit: 900000\n",
            "lower_limit: 900000 upper_limit: 975000\n",
            "lower_limit: 975000 upper_limit: 1050000\n",
            "lower_limit: 1050000 upper_limit: 1125000\n",
            "lower_limit: 1125000 upper_limit: 1200000\n",
            "lower_limit: 1200000 upper_limit: 1275000\n",
            "lower_limit: 1275000 upper_limit: 1350000\n",
            "lower_limit: 1350000 upper_limit: 1425000\n",
            "lower_limit: 1425000 upper_limit: 1500000\n",
            "lower_limit: 1500000 upper_limit: 1575000\n",
            "lower_limit: 1575000 upper_limit: 1575438\n",
            "['0_300000', '300000_600000', '600000_900000', '900000_1200000', '1200000_1500000', '1500000_1575438']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66vRsHcKAWyF",
        "colab_type": "text"
      },
      "source": [
        "### Import the so word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHGyO9D9QZC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import warnings\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "so_model = KeyedVectors.load_word2vec_format(so_model_file, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PvZAqO8k4lj",
        "colab_type": "text"
      },
      "source": [
        "### Inject similar words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JaSUKqccetw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inject_similar_words(process_number, words, injected_word_chunks):\n",
        "  start_time = dt.now()\n",
        "  for i in range(len(words)):\n",
        "    try:\n",
        "      words_to_inject = [words[i]]\n",
        "      similar_words = so_model.most_similar(words[i])\n",
        "      for similar_tuple in similar_words:\n",
        "        if similar_tuple[1] > 0.5:\n",
        "          words_to_inject.append(similar_tuple[0])\n",
        "      words[i] = \" \".join(words_to_inject)\n",
        "    except:\n",
        "      continue\n",
        "    if i % 10000 == 0:\n",
        "      t = dt.now() - start_time\n",
        "      start_time = dt.now()\n",
        "      print(\"CPU \" + str(process_number) + \": Processed: \" + str(i) + \" / \" + str(len(words)) + \" words in time: \", t)\n",
        "  injected_word_chunks[process_number] = words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Oaai2WHZTZ",
        "colab_type": "code",
        "outputId": "cdb27885-e659-4cea-c63e-69c284a9a04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "print(\"Available CPUs: \", mp.cpu_count())\n",
        "index = 0\n",
        "for word_chunks in file_chunks:\n",
        "  literature_chunk_name = \"/content/drive/My Drive/documents/projects/DeCaf/data/literature_chunks/\" + file_chunks_names[index] + \".txt\"\n",
        "  if not os.path.exists(literature_chunk_name):\n",
        "    print(\"Working on chunk: \", file_chunks_names[index])\n",
        "    manager = mp.Manager()\n",
        "    injected_word_chunks = manager.dict()\n",
        "    jobs = []\n",
        "\n",
        "    for i in range(len(word_chunks)):\n",
        "      p = mp.Process(target=inject_similar_words, args=(i, word_chunks[i], injected_word_chunks))\n",
        "      jobs.append(p)\n",
        "      p.start()\n",
        "\n",
        "    for proc in jobs:\n",
        "      proc.join()\n",
        "\n",
        "    injected_word_chunks = injected_word_chunks.values()\n",
        "\n",
        "    corpus = []\n",
        "    for chunk in injected_word_chunks:\n",
        "      corpus.append(\" \".join(chunk))\n",
        "    corpus = \" \".join(corpus)\n",
        "    literature = open(literature_chunk_name, 'w')\n",
        "    literature.write(corpus)\n",
        "    literature.close()\n",
        "  index = index + 1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available CPUs:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnuWn5XkCjfO",
        "colab_type": "text"
      },
      "source": [
        "### Concatenate and save the chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QrFDKRdCnOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(enhanced_literature_file):\n",
        "  chunks_directory = \"/content/drive/My Drive/documents/projects/DeCaf/data/literature_chunks/\"\n",
        "  print(chunks_names)\n",
        "  with open(enhanced_literature_file, 'w') as outfile:\n",
        "    for names in chunks_names:\n",
        "      with open(chunks_directory + names) as infile:\n",
        "        outfile.write(infile.read())\n",
        "      outfile.write(\" \")\n",
        "  print('File created!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnD4SBPUJSir",
        "colab_type": "text"
      },
      "source": [
        "## Create Word Embedding\n",
        "- Use fasttext for word embedding\n",
        "  - we take literature.txt as our input data.\n",
        "  - we train the classifier upsupervised since we just want to group the data according to the similarity.\n",
        "  - we have used skipgram as we have observe that skipgram models works better with subword information that cbow\n",
        "  - we are taking words with character number from 4-20. since we are removing every word less than three characters, its not important to take the characters less than 4 characters. Also, the design words seems to be on the bigger side. for ex. reproduceability contains 16 characters. we are considering characters upto 25 characters.\n",
        "  - We are taking 300 dimension of the words. Also looping for 10 epochs. Both because the training corpus is relatively small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8LPXDN4KJMH",
        "colab_type": "code",
        "outputId": "b40d72b9-caf1-425f-f5db-6580092d5b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2389317 sha256=8377c064a22b0c6932c1a4bb1eb82fdf5f30ae65fa7309f6c16c79420ca4c8af\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZ5xYWTbXoJ",
        "colab_type": "text"
      },
      "source": [
        "## Create Logging Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8H39Gum_Jy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def log(log_file_path, message):\n",
        "  file = pd.DataFrame([[str(dt.now()), 'info', message]], columns=['timestamp', 'type', 'message'])\n",
        "  if not os.path.exists(log_file_path):\n",
        "    file.to_csv(log_file_path)\n",
        "  else:\n",
        "    file.to_csv(log_file_path, mode='a', header=False)\n",
        "\n",
        "def log_result(log_file_path, message):\n",
        "  f = open(log_file_path, \"a\")\n",
        "  f.write(str(dt.now()))\n",
        "  f.write(message)\n",
        "  f.close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9GxG-n5SwdC",
        "colab_type": "text"
      },
      "source": [
        "## Train the `Word Embedding` model and save it as we.bin\n",
        "- Train and save the model if the model is not present\n",
        "- Load the model from disk if preselt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDHxShLcsFoa",
        "colab_type": "code",
        "outputId": "634adf4f-2d04-4034-f393-8a48a7a11ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import fasttext as ft\n",
        "\n",
        "log_file_path = \"/content/drive/My Drive/documents/projects/DeCaf/logs/we.csv\"\n",
        "we_log = []\n",
        "\n",
        "if not os.path.exists(enhanced_we_model_file_300d):\n",
        "  print(str(dt.now())+' Training Word Embedding model...')\n",
        "  we_log.append(str(dt.now())+' Training Word Embedding model...')\n",
        "  we_model = ft.train_unsupervised(enhanced_literature_file, \"skipgram\", minn=4, \\\n",
        "                                   maxn=25, dim=300, epoch=10)\n",
        "  we_model.save_model(enhanced_we_model_file_300d)\n",
        "  print(str(dt.now())+' Model trained and saved successfully')\n",
        "  we_log.append(str(dt.now())+' Model trained and saved successfully')\n",
        "else:\n",
        "  print(str(dt.now())+' Loading Word Embedding model from disk...')\n",
        "  we_log.append(str(dt.now())+' Loading Word Embedding model from disk...')\n",
        "  we_model = ft.load_model(enhanced_we_model_file_300d)\n",
        "  print(str(dt.now())+' Model loaded successfully.')\n",
        "  we_log.append(str(dt.now())+' Model loaded successfully.')\n",
        "\n",
        "log(log_file_path, \\\n",
        "    \"\\n\".join(we_log))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-09 02:49:32.534620 Training Word Embedding model...\n",
            "2020-04-09 08:35:44.445178 Model trained and saved successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ezQOGUS9JO",
        "colab_type": "text"
      },
      "source": [
        "## Playing around with the Word Embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgToIpCwXp5F",
        "colab_type": "text"
      },
      "source": [
        "Get the dimention of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XgUwC1mXsxb",
        "colab_type": "code",
        "outputId": "266b8e1e-a12d-4927-df6e-46206fccec90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "we_model.get_dimension()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGzgaNhGTFeV",
        "colab_type": "text"
      },
      "source": [
        "Get the words of the model... For a demo... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqgszQ6rXBmk",
        "colab_type": "code",
        "outputId": "e6f02ca3-e32c-4f2e-9101-ffb075e3fc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "we_model.get_words()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['systems',\n",
              " 'applications',\n",
              " 'software',\n",
              " 'therefore',\n",
              " 'programs',\n",
              " 'objects',\n",
              " 'softwares',\n",
              " 'avionics',\n",
              " 'hardware',\n",
              " 'since',\n",
              " 'hardware/software',\n",
              " 'program',\n",
              " 'sofware',\n",
              " 's/w',\n",
              " 'software/hardware',\n",
              " 'development',\n",
              " 'application',\n",
              " 'developers',\n",
              " 'object',\n",
              " 'need',\n",
              " 'uses',\n",
              " 'otherwise',\n",
              " 'values',\n",
              " 'either',\n",
              " 'means',\n",
              " 'actually',\n",
              " 'data',\n",
              " 'want',\n",
              " 'defines',\n",
              " 'architecture',\n",
              " 'corresponding',\n",
              " 'architectural',\n",
              " 'information',\n",
              " 'entities',\n",
              " 'system',\n",
              " 'model',\n",
              " 'sytems',\n",
              " 'class',\n",
              " 'process',\n",
              " 'multiple',\n",
              " 'must',\n",
              " 'designing',\n",
              " 'always',\n",
              " 'two',\n",
              " 'supports',\n",
              " 'records',\n",
              " 'classes',\n",
              " 'table',\n",
              " 'methodology',\n",
              " 'techniques',\n",
              " 'given',\n",
              " 'use',\n",
              " 'used',\n",
              " 'using',\n",
              " 'tests',\n",
              " 'collection',\n",
              " 'defined',\n",
              " 'approaches',\n",
              " 'instance',\n",
              " 'record',\n",
              " 'will',\n",
              " 'constructor',\n",
              " 'database',\n",
              " 'models',\n",
              " 'three',\n",
              " 'testing',\n",
              " 'processes',\n",
              " 'service',\n",
              " 'design',\n",
              " 'test',\n",
              " 'associated',\n",
              " 'strategies',\n",
              " 'task',\n",
              " 'approach',\n",
              " 'fact',\n",
              " 'environments',\n",
              " 'computers',\n",
              " 'customer',\n",
              " 'method',\n",
              " 'wish',\n",
              " 'required',\n",
              " 'designs',\n",
              " 'appropriate',\n",
              " 'environment',\n",
              " 'provides',\n",
              " 'machines',\n",
              " 'technique',\n",
              " 'specific',\n",
              " 'engineers',\n",
              " 'meaning',\n",
              " 'next',\n",
              " 'allows',\n",
              " 'architectual',\n",
              " 'particular',\n",
              " 'statistical',\n",
              " 'ood',\n",
              " 'ui/ux',\n",
              " 'platforms',\n",
              " 'association',\n",
              " 'redesign',\n",
              " 'separate',\n",
              " 'necessary',\n",
              " 'methods',\n",
              " 'cases',\n",
              " 'last',\n",
              " 're-design',\n",
              " 'unless',\n",
              " 'strategy',\n",
              " 'services',\n",
              " 'sub-processes',\n",
              " 'proccesses',\n",
              " 'also',\n",
              " 'case',\n",
              " 'learn',\n",
              " 'subclasses',\n",
              " 'db',\n",
              " 'architectures',\n",
              " 'dataset',\n",
              " 'specifications',\n",
              " 'controller',\n",
              " 'desing',\n",
              " 'dev',\n",
              " 'needs',\n",
              " 'requirements',\n",
              " 'aspects',\n",
              " 'teaching',\n",
              " 'however',\n",
              " 'individual',\n",
              " 'available',\n",
              " 'academic',\n",
              " 'correspond',\n",
              " 'learning',\n",
              " 'several',\n",
              " 'subsystem',\n",
              " 'first',\n",
              " 'called',\n",
              " 'thus',\n",
              " 'needed',\n",
              " 'system/browser',\n",
              " 'sytem',\n",
              " 'system/hardware',\n",
              " 'systen',\n",
              " 'os',\n",
              " 'production',\n",
              " 'effectiveness',\n",
              " 'organization',\n",
              " 'thread',\n",
              " 'integer',\n",
              " 'many',\n",
              " 'depend',\n",
              " 'second',\n",
              " 'way',\n",
              " 'capabilities',\n",
              " 'capability',\n",
              " 'result',\n",
              " 'built-in',\n",
              " 'datas',\n",
              " 'scenarios',\n",
              " 'one',\n",
              " 'entity',\n",
              " 'development/testing',\n",
              " 'various',\n",
              " 'devlopment',\n",
              " 'develpment',\n",
              " 'developement',\n",
              " 'developpement',\n",
              " 'develoment',\n",
              " 'developemnt',\n",
              " 'projects',\n",
              " 'sub-process',\n",
              " 'programmers',\n",
              " 'proccess',\n",
              " 'proces',\n",
              " 'processs',\n",
              " 'project',\n",
              " 'script',\n",
              " 'customers',\n",
              " 'issues',\n",
              " 'referred',\n",
              " 'code',\n",
              " 'codes',\n",
              " 'routine',\n",
              " 'sub-project',\n",
              " 'proejct',\n",
              " 'may',\n",
              " 'methodologies',\n",
              " 'company',\n",
              " 'c-code',\n",
              " 'python-code',\n",
              " 'different',\n",
              " 'able',\n",
              " 'every',\n",
              " 'viewmodel',\n",
              " 'dto',\n",
              " 'containing',\n",
              " 'mining',\n",
              " 'define',\n",
              " 'simply',\n",
              " 'testcases',\n",
              " 'find',\n",
              " 'paradigms',\n",
              " 'interfaces',\n",
              " 'frameworks',\n",
              " 'component',\n",
              " 'server',\n",
              " 'views',\n",
              " 'people',\n",
              " 'determines',\n",
              " 'specified',\n",
              " 'problems',\n",
              " 'course',\n",
              " 'architects',\n",
              " 'infrastructure',\n",
              " 'studies',\n",
              " 'users',\n",
              " '2nd',\n",
              " 'higher',\n",
              " 'developed',\n",
              " 'study',\n",
              " '1st',\n",
              " 'based',\n",
              " 'algorithms',\n",
              " 'use-case',\n",
              " 'via',\n",
              " 'show',\n",
              " 'property',\n",
              " 'problem',\n",
              " 'modules',\n",
              " 'utilized',\n",
              " 'just',\n",
              " 'provide',\n",
              " 'respective',\n",
              " 'still',\n",
              " 'solution',\n",
              " 'shown',\n",
              " 'even',\n",
              " 'utilizing',\n",
              " 'includes',\n",
              " 'details',\n",
              " 'papers',\n",
              " 'independent',\n",
              " 'testsuite',\n",
              " 'engineering',\n",
              " 'engineer',\n",
              " 'often',\n",
              " 'goals',\n",
              " 'economics',\n",
              " 'analyse',\n",
              " 'analysing',\n",
              " 'hence',\n",
              " 'analyze',\n",
              " 'described',\n",
              " 'worked',\n",
              " 'depends',\n",
              " 'works',\n",
              " 'fields',\n",
              " 'work',\n",
              " 'companies',\n",
              " 'working',\n",
              " 'supported',\n",
              " 'issue',\n",
              " 'previous',\n",
              " 'represents',\n",
              " 'representing',\n",
              " 'apps',\n",
              " 'app',\n",
              " 'studying',\n",
              " 'generally',\n",
              " 'sum',\n",
              " 'providing',\n",
              " 'infomation',\n",
              " 'informations',\n",
              " 'info',\n",
              " 'infos',\n",
              " 'inforamtion',\n",
              " 'understand',\n",
              " 'analyzing',\n",
              " 'changed',\n",
              " 'day',\n",
              " 'displayed',\n",
              " 'length',\n",
              " 'mechanisms',\n",
              " 'scenario',\n",
              " 'accuracy',\n",
              " 'require',\n",
              " 'fourth',\n",
              " 'oses',\n",
              " 'engeneer',\n",
              " 'functionality',\n",
              " 'numbers',\n",
              " 'serivce',\n",
              " 'sevice',\n",
              " 'dependent',\n",
              " 'possibilities',\n",
              " 'actual',\n",
              " 'necessarily',\n",
              " 'efficiency',\n",
              " 'contains',\n",
              " 'discussed',\n",
              " 'organisation',\n",
              " 'function',\n",
              " 'theoretical',\n",
              " 'context',\n",
              " 'relations',\n",
              " 'relationships',\n",
              " 're-engineering',\n",
              " 'analyses',\n",
              " 'output',\n",
              " 'computation',\n",
              " 'analysis',\n",
              " 'knowledge',\n",
              " 'shall',\n",
              " 'similarly',\n",
              " 'enginering',\n",
              " 'enginnering',\n",
              " 'engineered',\n",
              " 'engeneering',\n",
              " 'engg',\n",
              " 'situations',\n",
              " 'tooling',\n",
              " 'testcase',\n",
              " 'test-case',\n",
              " 'coders',\n",
              " 'time',\n",
              " 'estimating',\n",
              " 'tets',\n",
              " '-test',\n",
              " 'testmethod1',\n",
              " 'smoketest',\n",
              " 'rows',\n",
              " 'according',\n",
              " 'undergraduate',\n",
              " 'developing',\n",
              " 'figure',\n",
              " 'number',\n",
              " 'though',\n",
              " 'contain',\n",
              " 'components',\n",
              " 'current',\n",
              " 'expertise',\n",
              " 'differing',\n",
              " 'meta-information',\n",
              " 'servers',\n",
              " 'metadata',\n",
              " 'depending',\n",
              " 'creating',\n",
              " 'count',\n",
              " 'included',\n",
              " 'reverse-engineering',\n",
              " 'seconds',\n",
              " 'associations',\n",
              " 'indeed',\n",
              " 'devs',\n",
              " 'requirement',\n",
              " 'aka',\n",
              " 'differ',\n",
              " 'create',\n",
              " 'add',\n",
              " 'identify',\n",
              " 'change',\n",
              " 'constructors',\n",
              " 'built',\n",
              " 'probably',\n",
              " 'algorithmic',\n",
              " 'usually',\n",
              " 'provided',\n",
              " 'holds',\n",
              " 'unit-testing',\n",
              " 'infromation',\n",
              " 'discern',\n",
              " 'hour',\n",
              " 'certain',\n",
              " 'array',\n",
              " 'third',\n",
              " 'sub-components',\n",
              " 'mentioned',\n",
              " 'especially',\n",
              " 'although',\n",
              " 'consequently',\n",
              " 'specifies',\n",
              " 'user',\n",
              " 'shows',\n",
              " 'likely',\n",
              " 'bugs',\n",
              " 'functions',\n",
              " 'accordance',\n",
              " 'changes',\n",
              " 'staff',\n",
              " 'myclass',\n",
              " 'include',\n",
              " 'measurements',\n",
              " 'teams',\n",
              " 'showed',\n",
              " 'determined',\n",
              " 'private',\n",
              " 'controls',\n",
              " 'determine',\n",
              " 'team',\n",
              " 'displays',\n",
              " 'utilities',\n",
              " 'supply',\n",
              " 'outcome',\n",
              " 'experience',\n",
              " 'develop',\n",
              " 'integrating',\n",
              " 'university',\n",
              " 'levels',\n",
              " 'amount',\n",
              " 'libraries',\n",
              " 'technics',\n",
              " 'experimentation',\n",
              " 'tools',\n",
              " 'investigations',\n",
              " 'displaying',\n",
              " 'single',\n",
              " 'minute',\n",
              " 'tool',\n",
              " 'analisys',\n",
              " 'projec',\n",
              " 'proyect',\n",
              " 'webproject',\n",
              " 'porject',\n",
              " 'projekt',\n",
              " 'projet',\n",
              " 'prject',\n",
              " 'situation',\n",
              " 'programme',\n",
              " 'practical',\n",
              " 'present',\n",
              " 'computations',\n",
              " 'computational',\n",
              " 'behave',\n",
              " 'results',\n",
              " 'column',\n",
              " 'skills',\n",
              " 'technology',\n",
              " 'academia',\n",
              " 'demands',\n",
              " 'know-how',\n",
              " 'frame-rate',\n",
              " 'set',\n",
              " 'conditions',\n",
              " 'security',\n",
              " 'ability',\n",
              " 'contained',\n",
              " 'orders',\n",
              " 'programming',\n",
              " 'analyser',\n",
              " 'investigation',\n",
              " 'button',\n",
              " 'sections',\n",
              " 'understanding',\n",
              " 'researched',\n",
              " 'composed',\n",
              " 'building',\n",
              " 'larger',\n",
              " 'requires',\n",
              " 'circumstances',\n",
              " 'resutls',\n",
              " 'resuls',\n",
              " 'features',\n",
              " 'type',\n",
              " 'familiarity',\n",
              " 'value',\n",
              " '30mins',\n",
              " 'generates',\n",
              " 'showing',\n",
              " 'requirments',\n",
              " 'obviously',\n",
              " 'generate',\n",
              " 'requeriments',\n",
              " 'lacks',\n",
              " 'analyis',\n",
              " 'wok',\n",
              " 'college',\n",
              " 'person',\n",
              " '15mins',\n",
              " '10min',\n",
              " 'tactics',\n",
              " 'organisations',\n",
              " '10seconds',\n",
              " 'defining',\n",
              " '25ms',\n",
              " '2min',\n",
              " 'allow',\n",
              " 'discuss',\n",
              " 'sharpness',\n",
              " 'solutions',\n",
              " 'explained',\n",
              " 'empirical',\n",
              " 'represented',\n",
              " 'describes',\n",
              " 'types',\n",
              " 'use-cases',\n",
              " 'figured',\n",
              " 'when',\n",
              " 'additional',\n",
              " 'textbox',\n",
              " 'differnt',\n",
              " 'diffrent',\n",
              " 'diferent',\n",
              " 'research',\n",
              " 'managing',\n",
              " 'modeling',\n",
              " 'useful',\n",
              " 'academics',\n",
              " 'effectively',\n",
              " 'exercising',\n",
              " 'organizations',\n",
              " 'products',\n",
              " 'mentions',\n",
              " 'row',\n",
              " 'general',\n",
              " 'testing/development',\n",
              " 'subclass',\n",
              " 'initial',\n",
              " 'tesing',\n",
              " 'testings',\n",
              " 'testing/mocking',\n",
              " 'testing/debugging',\n",
              " 'stages',\n",
              " 'packages',\n",
              " 'senior',\n",
              " 'researchers',\n",
              " 'generated',\n",
              " 'education',\n",
              " 'exemple',\n",
              " 'four',\n",
              " 'example',\n",
              " 'exmaple',\n",
              " 'technological',\n",
              " 'difficulties',\n",
              " 'n',\n",
              " 'figuring',\n",
              " 'variable',\n",
              " 'modest',\n",
              " 'ways',\n",
              " 'produced',\n",
              " 'researching',\n",
              " 'literature',\n",
              " 'chapter',\n",
              " 'consists',\n",
              " 'predictability',\n",
              " 'quite',\n",
              " 'clients',\n",
              " 'scientists',\n",
              " 'feasible',\n",
              " 'framerates',\n",
              " 'quality',\n",
              " 'fidelity',\n",
              " 'original',\n",
              " 'quality/size',\n",
              " 'low-quality',\n",
              " 'compressibility',\n",
              " 'size/quality',\n",
              " 'reasoning',\n",
              " 'intend',\n",
              " 'tasks',\n",
              " 'protection',\n",
              " 'aproach',\n",
              " 'appraoch',\n",
              " 'approch',\n",
              " 'apporach',\n",
              " 'abstract',\n",
              " 'privacy',\n",
              " 'teach',\n",
              " 'columns',\n",
              " 'graduate',\n",
              " 'complicated',\n",
              " 'layer',\n",
              " 'explain',\n",
              " 'modeled',\n",
              " 'executed',\n",
              " 'alluded',\n",
              " 'attributes',\n",
              " 'changing',\n",
              " 'apis',\n",
              " 'mechanism',\n",
              " 'basing',\n",
              " 'considered',\n",
              " 'elements',\n",
              " 'outside',\n",
              " 'concepts',\n",
              " 'nubmer',\n",
              " 'numer',\n",
              " 'nuber',\n",
              " 'oop',\n",
              " 'authentication',\n",
              " 'offer',\n",
              " 'expectations',\n",
              " 'expert',\n",
              " 'enables',\n",
              " 'security/privacy',\n",
              " 'functionalities',\n",
              " 'lots',\n",
              " 'finding',\n",
              " 'principles',\n",
              " 'paragraph',\n",
              " 'outlined',\n",
              " 'pinpoint',\n",
              " 'digging',\n",
              " 'feature',\n",
              " 'identifying',\n",
              " 'management',\n",
              " 'pattern',\n",
              " 'mathematics',\n",
              " 'compatible',\n",
              " 'static',\n",
              " 'element',\n",
              " 'tables',\n",
              " 'best',\n",
              " 'derived',\n",
              " 'specifically',\n",
              " 'better',\n",
              " 'good',\n",
              " 'developpers',\n",
              " 'developer',\n",
              " 'thereby',\n",
              " 'typically',\n",
              " 'siggraph',\n",
              " 'indicated',\n",
              " 'without',\n",
              " 'appeared',\n",
              " 'rather',\n",
              " 'including',\n",
              " 'easy',\n",
              " 'updated',\n",
              " 'guidelines',\n",
              " 'repositories',\n",
              " 'retrieve',\n",
              " 'googling',\n",
              " 'ten',\n",
              " 'small',\n",
              " 'supporting',\n",
              " 'eight',\n",
              " 'requierements',\n",
              " 'seven',\n",
              " 'six',\n",
              " 'requierments',\n",
              " 'methods/functions',\n",
              " 'studied',\n",
              " 'careful',\n",
              " 'generating',\n",
              " 'secuirty',\n",
              " 'sercurity',\n",
              " 'securty',\n",
              " 'secruity',\n",
              " 'secutiry',\n",
              " 'securtiy',\n",
              " 'metric',\n",
              " 'institute',\n",
              " 'created',\n",
              " 'reasearch',\n",
              " 'involve',\n",
              " 'considerations',\n",
              " 'professionals',\n",
              " 'student',\n",
              " 'supplies',\n",
              " 'five',\n",
              " 'parts',\n",
              " 'facilities',\n",
              " 'subtype',\n",
              " 'reliability',\n",
              " 'technical',\n",
              " 'participants',\n",
              " 'support',\n",
              " 'operations',\n",
              " 'manage',\n",
              " 'introductory',\n",
              " 'proofs',\n",
              " 'integrated',\n",
              " 'consist',\n",
              " 'paradigm',\n",
              " 'specification',\n",
              " 'modelling',\n",
              " 'discusses',\n",
              " 'complications',\n",
              " 'subjects',\n",
              " 'practices',\n",
              " 'non-developers',\n",
              " 'enterprise-level',\n",
              " 'consisting',\n",
              " 'discussing',\n",
              " 'developping',\n",
              " 'costs',\n",
              " 'students',\n",
              " 'categories',\n",
              " 'calss',\n",
              " 'clas',\n",
              " 'member',\n",
              " 'familiarize',\n",
              " 'classe',\n",
              " 'classs',\n",
              " 'found',\n",
              " 'executable',\n",
              " 'suported',\n",
              " 'referenced',\n",
              " 'account',\n",
              " 'folks',\n",
              " 'specify',\n",
              " 'large',\n",
              " 'compositional',\n",
              " 'related',\n",
              " 'concept',\n",
              " 'declared',\n",
              " 'handful',\n",
              " 'instead',\n",
              " 'added',\n",
              " 'phase',\n",
              " 'ideal',\n",
              " 'determining',\n",
              " 'associate',\n",
              " 'pertaining',\n",
              " 'programmer',\n",
              " 'applies',\n",
              " 'typical',\n",
              " 'item',\n",
              " 'controllers',\n",
              " 'mehtod',\n",
              " 'methode',\n",
              " 'mehod',\n",
              " '-method',\n",
              " 'metod',\n",
              " 'methos',\n",
              " 'method-',\n",
              " 'impossible',\n",
              " 'decoupling',\n",
              " 'psychology',\n",
              " 'appearing',\n",
              " 'alternatives',\n",
              " 'state',\n",
              " 'states',\n",
              " 'workstation',\n",
              " 'researches',\n",
              " 'level',\n",
              " 'discussions',\n",
              " 'reseach',\n",
              " 'computer',\n",
              " 'invoked',\n",
              " 'identified',\n",
              " 'undergrad',\n",
              " 'actions',\n",
              " 'sequence',\n",
              " 'c-program',\n",
              " 'progam',\n",
              " 'java-program',\n",
              " 'programm',\n",
              " 'programe',\n",
              " 'accessible',\n",
              " 'machine',\n",
              " 'informatics',\n",
              " 'practice',\n",
              " 'declare',\n",
              " 'prices',\n",
              " 'probabilistic',\n",
              " 'departments',\n",
              " 'prog',\n",
              " 'overheads',\n",
              " 'principle',\n",
              " 'big',\n",
              " 'login',\n",
              " 'occasions',\n",
              " 'webservice',\n",
              " 'web-service',\n",
              " 'measurement',\n",
              " 'lan',\n",
              " 'instances',\n",
              " 'mathematical',\n",
              " 'implementations',\n",
              " 'applied',\n",
              " 'detect',\n",
              " 'denoting',\n",
              " 'languages',\n",
              " 'influence',\n",
              " 'penalty',\n",
              " 'idiom',\n",
              " 'greater',\n",
              " 'cost',\n",
              " 'inside',\n",
              " 'earlier',\n",
              " 'risks',\n",
              " 'attribute',\n",
              " 'category',\n",
              " 'workers',\n",
              " 'possible',\n",
              " 'researcher',\n",
              " 'efficient',\n",
              " 'page',\n",
              " 'issuse',\n",
              " 'idioms',\n",
              " 'lowered',\n",
              " 'potentially',\n",
              " 'implemented',\n",
              " 'elegant',\n",
              " 'sciences',\n",
              " 'widgets',\n",
              " 'conceptual',\n",
              " 'implications',\n",
              " 'department',\n",
              " 'structures',\n",
              " 'devops',\n",
              " 'global',\n",
              " 'patter',\n",
              " 'patten',\n",
              " 'patterns',\n",
              " 'patters',\n",
              " 'webapp',\n",
              " 'aplication',\n",
              " 'appliction',\n",
              " 'applicaton',\n",
              " 'applcation',\n",
              " 'applicaiton',\n",
              " 'measure',\n",
              " 'extremely',\n",
              " 'behaviors',\n",
              " 'important',\n",
              " 'activities',\n",
              " 'reults',\n",
              " 'result-set',\n",
              " 'resuts',\n",
              " 'optimal',\n",
              " 'rarely',\n",
              " 'knowlege',\n",
              " 'cross-functional',\n",
              " 'servie',\n",
              " 'servcie',\n",
              " 'serice',\n",
              " 'teachers',\n",
              " 'avoid',\n",
              " 'variety',\n",
              " 'employees',\n",
              " 'troubles',\n",
              " 'indices',\n",
              " 'numerous',\n",
              " 'tdd',\n",
              " 'pc',\n",
              " 'overhead',\n",
              " 'div',\n",
              " 'really',\n",
              " 'irrelevant',\n",
              " 'text',\n",
              " 'namely',\n",
              " 'courses',\n",
              " 'apply',\n",
              " 'possibility',\n",
              " 'allowing',\n",
              " 'applying',\n",
              " 'username',\n",
              " 'trying',\n",
              " 'huge',\n",
              " 'sufficient',\n",
              " 'structs',\n",
              " 'suport',\n",
              " 'philosophy',\n",
              " 'relates',\n",
              " 'laptop',\n",
              " 'delegates',\n",
              " 'topics',\n",
              " 'stage',\n",
              " 'hinted',\n",
              " 'describing',\n",
              " 'interesting',\n",
              " 'lead',\n",
              " 'priority',\n",
              " 'write',\n",
              " 'introduction',\n",
              " 'generalization',\n",
              " 'langauge',\n",
              " 'language',\n",
              " 'selected',\n",
              " 'robustness',\n",
              " 'subsections',\n",
              " 'his/her',\n",
              " 'sites',\n",
              " 'concerning',\n",
              " 'benefit',\n",
              " 'int',\n",
              " 'reasonable',\n",
              " 'subsection',\n",
              " 'sub-section',\n",
              " 'portion',\n",
              " 'complex',\n",
              " 'helpful',\n",
              " 'represent',\n",
              " 'bigger',\n",
              " 'textbook',\n",
              " 'share',\n",
              " 'trivial',\n",
              " 'executing',\n",
              " 'abilities',\n",
              " 'separately',\n",
              " 'put',\n",
              " 'accessors',\n",
              " 'threads',\n",
              " 'items',\n",
              " 'conferences',\n",
              " 'fist',\n",
              " 'furthermore',\n",
              " 'expensive',\n",
              " 'considering',\n",
              " 'performed',\n",
              " 'impact',\n",
              " 'aplied',\n",
              " 'applyed',\n",
              " 'he/she',\n",
              " 'user1',\n",
              " 'identifies',\n",
              " 'section',\n",
              " 'unimportant',\n",
              " 'scope',\n",
              " 'smaller',\n",
              " 'viewmodels',\n",
              " 'presumably',\n",
              " 'lowering',\n",
              " 'crucial',\n",
              " 'display',\n",
              " 'answers',\n",
              " 'offers',\n",
              " 'technologies',\n",
              " 'evaluated',\n",
              " 'give',\n",
              " 'subsequently',\n",
              " 'properties',\n",
              " 'practise',\n",
              " 'sub-models',\n",
              " 'submodels',\n",
              " 'methodes',\n",
              " 'metods',\n",
              " 'call',\n",
              " 'appear',\n",
              " 'library',\n",
              " 'coursework',\n",
              " 'debuggers',\n",
              " 'sku',\n",
              " 'product',\n",
              " 'contributors',\n",
              " 'tuple',\n",
              " 'importance',\n",
              " 'arise',\n",
              " 'individually',\n",
              " 'denotes',\n",
              " 'additionally',\n",
              " 'risk',\n",
              " 'criteria',\n",
              " 'fifth',\n",
              " 'creation',\n",
              " 'offshore',\n",
              " 'makes',\n",
              " 'endpoints',\n",
              " 'increases',\n",
              " 'admins',\n",
              " 'quantity',\n",
              " 'calling',\n",
              " 'scrum',\n",
              " 'think',\n",
              " 'accounts',\n",
              " 'sizable',\n",
              " 'practitioners',\n",
              " 'consultants',\n",
              " 'essential',\n",
              " 'performance',\n",
              " 'preferable',\n",
              " 'complexity',\n",
              " 'tend',\n",
              " 'generation',\n",
              " 'interact',\n",
              " 'books',\n",
              " 'grouping',\n",
              " 'intefaces',\n",
              " 'inteface',\n",
              " 'interace',\n",
              " 'interface',\n",
              " 'common',\n",
              " 'terms',\n",
              " 'hiccups',\n",
              " 'nodes',\n",
              " 'iteration',\n",
              " 'among',\n",
              " 'skus',\n",
              " 'consequence',\n",
              " 'compared',\n",
              " 'describe',\n",
              " 'addressed',\n",
              " 'involves',\n",
              " 'implies',\n",
              " 'relating',\n",
              " 'restricted',\n",
              " 'speed',\n",
              " 'impacts',\n",
              " 'modify',\n",
              " 'biology',\n",
              " 'sdlc',\n",
              " 'plug-ins',\n",
              " 'words',\n",
              " 'decision',\n",
              " 'vital',\n",
              " 'players',\n",
              " 'identification',\n",
              " 'client',\n",
              " 'creates',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfDXAMsiXizi",
        "colab_type": "text"
      },
      "source": [
        "Get the vector of a word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwQIRXXdXWJL",
        "colab_type": "code",
        "outputId": "400b736b-8904-46f2-f25b-c13507db1b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "we_model.get_word_vector('Maintainability')[0:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07752886, -0.19894521, -0.1421423 , -0.32111043, -0.48004603,\n",
              "       -0.06075421, -0.12335577,  0.12761173, -0.37535232,  0.15787311,\n",
              "        0.05555912, -0.44184476, -0.39095154, -0.1285222 ,  0.00115345,\n",
              "        0.2644709 ,  0.22110255,  0.02852138,  0.26432577, -0.33611   ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmzrg38PXzxt",
        "colab_type": "text"
      },
      "source": [
        "Get the vector of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otivEp_7X3I-",
        "colab_type": "code",
        "outputId": "5875b608-7d83-43b8-e376-90ead23a954e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vector = we_model.get_sentence_vector(\"Add performance tracker to active admin jobs\")\n",
        "print(vector.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300,)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}