{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelTrainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue-brQOCOR4A",
        "colab_type": "text"
      },
      "source": [
        "# Notebook for the experiment of building **DeCaf** (**De**sign **C**l**a**ssi**f**ier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_wliyuuasNx",
        "colab_type": "text"
      },
      "source": [
        "## Architectural Overview/Design\n",
        "In Progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up9iaDnZM9l",
        "colab_type": "text"
      },
      "source": [
        "## Objective\n",
        "The main objective is to train the models with the train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A-ie768Gp-2",
        "colab_type": "code",
        "outputId": "fcbb7e27-db35-40f3-d9ec-4957d173b825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhpmkYb5NWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def log(log_file_path, message):\n",
        "  file = pd.DataFrame([[str(dt.now()), 'info', message]], columns=['timestamp', 'type', 'message'])\n",
        "  if not os.path.exists(log_file_path):\n",
        "    file.to_csv(log_file_path)\n",
        "  else:\n",
        "    file.to_csv(log_file_path, mode='a', header=False)\n",
        "\n",
        "def log_result(log_file_path, message):\n",
        "  f = open(log_file_path, \"a\")\n",
        "  f.write(str(dt.now()))\n",
        "  f.write(message)\n",
        "  f.close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04B0o9uz3gce",
        "colab_type": "text"
      },
      "source": [
        "## Load training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxt9vaSQ3kCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_Q_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/X_Q.npy\"\n",
        "Y_Q_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/Y_Q.npy\"\n",
        "\n",
        "X_A_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/X_A.npy\"\n",
        "Y_A_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/Y_A.npy\"\n",
        "\n",
        "X_C_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/X_C.npy\"\n",
        "Y_C_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/Y_C.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9gkg8dEI5fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Q = np.load(X_Q_url)\n",
        "Y_Q = np.load(Y_Q_url)\n",
        "\n",
        "X_A = np.load(X_A_url)\n",
        "Y_A = np.load(Y_A_url)\n",
        "\n",
        "X_C = np.load(X_C_url)\n",
        "Y_C = np.load(Y_C_url)\n",
        "\n",
        "X = np.concatenate((X_Q, X_A, X_C), axis=0)\n",
        "Y = np.concatenate((Y_Q, Y_A, Y_C), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xvFVF1kL4N4I"
      },
      "source": [
        "### Examine X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9f465792-6943-45b8-d575-859d2bbad5d3",
        "id": "H8w6rVqo4P0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200000, 300)\n",
            "(200000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyL6iWCiNlwR",
        "colab_type": "text"
      },
      "source": [
        "## Training Traditional Data Mining Algorithms\n",
        "- Before start experimenting with deep learning, we start our experiment with training some traditional data mining algorithms. We are taking the following classifiers with notations and parameter configurations:\n",
        "  - k-Nearest Neighbors (`knn`)\n",
        "  - Decision Tree (`dt`)\n",
        "  - Random Forest (`rf`)\n",
        "  - Logistic Regression (`lr`)\n",
        "  - Linear SVM (`lsvm`)\n",
        "    - C = Regularization Parameter\n",
        "  - RBF SVM (`rbf_svm`)\n",
        "    - Kernel coefficient = 2 \n",
        "    - Regularization parameter = default = 1\n",
        "  - Neural Net (`nn`)\n",
        "  - AdaBoost (`ab`)\n",
        "  - Naive Bayes (`gnb`)\n",
        "  - QDA (`qda`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-7yQzbVCW7",
        "colab_type": "text"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KML4RtuuRum4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq7d0YOLVF6K",
        "colab_type": "text"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsab_DKqQAak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "classifier_names = [\n",
        "      \"Nearest Neighbors\",\n",
        "      \"Decision Tree\",\n",
        "      \"Random Forest\",\n",
        "      \"Logistic Regression\",\n",
        "      \"Gaussian Naive Bayes\", \n",
        "      \"Neural Net\", \n",
        "      \"AdaBoost\",\n",
        "      \"QDA\",    \n",
        "      \"Linear SVM\", \n",
        "      \"RBF SVM\",\n",
        "]\n",
        "\n",
        "model_paths = [\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/knn.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/dt.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/rf.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/lr.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/gnb.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/nn.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/ab.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/qda.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/lsvm.joblib\",\n",
        "      \"/content/drive/My Drive/documents/projects/DeCaf/models/rbf_svm.joblib\"\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "      KNeighborsClassifier(n_jobs=-1),\n",
        "      DecisionTreeClassifier(), \n",
        "      RandomForestClassifier(n_jobs=-1), \n",
        "      LogisticRegression(max_iter=50000),\n",
        "      GaussianNB(),\n",
        "      MLPClassifier(max_iter=4000),\n",
        "      AdaBoostClassifier(),\n",
        "      QuadraticDiscriminantAnalysis(),\n",
        "      SVC(kernel=\"linear\", C=0.025), \n",
        "      SVC(gamma=2, C=1)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9Q0fquUXt8c",
        "colab_type": "text"
      },
      "source": [
        "### Combine the three train data namely: `questions`, `answers` and `comment`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj2e6MSCX9Gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate((X_Q, X_A, X_C), axis=0)\n",
        "Y = np.concatenate((Y_Q, Y_A, Y_C), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TozZfIXeYaw2",
        "colab_type": "text"
      },
      "source": [
        "### Examine X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbxIWifrYfYS",
        "colab_type": "code",
        "outputId": "558e8be5-2218-4143-d9cd-7720ee7a598b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200000, 300)\n",
            "(200000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kV5XMI7PYOP",
        "colab_type": "text"
      },
      "source": [
        "### **Train** and **Save** the models into memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcKOKkyj7Nep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from joblib import dump, load\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "\n",
        "def train_dm_models(X, Y, process_number, classifier, classifier_name, model_path):\n",
        "  logs = []\n",
        "  if not os.path.exists(model_path):\n",
        "    start_time = dt.now()\n",
        "    print(str(start_time) + \" Started training model: \", classifier_name)\n",
        "    logs.append(str(start_time) + \" Started training model: \" + classifier_name)\n",
        "    model = classifier.fit(X, Y)\n",
        "    end_time = dt.now()\n",
        "    print(str(end_time) + \" Finished training model: \", classifier_name)\n",
        "    logs.append(str(end_time) + \" Finished training model: \" + classifier_name)\n",
        "    print(\"Time to train model: \" + classifier_name + \": \" + str(end_time - start_time))\n",
        "    logs.append(\"Time to train model: \" + classifier_name + \": \" + str(end_time - start_time))\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    dump(model, model_path)\n",
        "    log(\"/content/drive/My Drive/documents/projects/DeCaf/logs/model_train.csv\", \"\\n\".join(logs))\n",
        "  else: \n",
        "    print(\"Model already present at \", model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQswNls3VuOm",
        "colab_type": "code",
        "outputId": "0710e5d8-f390-47e9-9814-b5f07a34c4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "print(\"Available CPUs: \", mp.cpu_count())\n",
        "\n",
        "jobs = []\n",
        "for index, classifier in enumerate(classifiers):\n",
        "  p = mp.Process(target=train_dm_models, args=(X, Y, index, classifier, classifier_names[index], model_paths[index]))\n",
        "  jobs.append(p)\n",
        "  p.start()\n",
        "\n",
        "for proc in jobs:\n",
        "  proc.join()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available CPUs:  4\n",
            "2020-04-05 11:14:13.383082 Started training model:  Nearest Neighbors\n",
            "2020-04-05 11:14:13.455925 Started training model:  Decision Tree\n",
            "2020-04-05 11:14:13.529344 Started training model:  Random Forest\n",
            "2020-04-05 11:14:13.607297 Started training model:  Logistic Regression\n",
            "2020-04-05 11:14:13.713409 Started training model:  Gaussian Naive Bayes\n",
            "2020-04-05 11:14:13.786545 Started training model:  Neural Net\n",
            "2020-04-05 11:14:13.909944 Started training model:  AdaBoost\n",
            "2020-04-05 11:14:13.985187 Started training model:  QDA\n",
            "2020-04-05 11:14:14.117301 Started training model:  Linear SVM\n",
            "2020-04-05 11:14:14.236641 Started training model:  RBF SVM\n",
            "2020-04-05 11:14:22.209939 Finished training model:  Gaussian Naive Bayes\n",
            "Time to train model: Gaussian Naive Bayes: 0:00:08.496530\n",
            "----------------------------------------------------------\n",
            "2020-04-05 11:16:05.566355 Finished training model:  Logistic Regression\n",
            "Time to train model: Logistic Regression: 0:01:51.959058\n",
            "----------------------------------------------------------\n",
            "2020-04-05 11:16:16.071370 Finished training model:  QDA\n",
            "Time to train model: QDA: 0:02:02.086183\n",
            "----------------------------------------------------------\n",
            "2020-04-05 11:18:40.593015 Finished training model:  Nearest Neighbors\n",
            "Time to train model: Nearest Neighbors: 0:04:27.209933\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-05 11:21:37.987047 Finished training model:  Neural Net\n",
            "Time to train model: Neural Net: 0:07:24.200502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process Process-145:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-68-de3e54a1af8a>\", line 11, in train_dm_models\n",
            "    model = classifier.fit(X, Y)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\", line 383, in fit\n",
            "    for i, t in enumerate(trees))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1017, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 909, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 638, in get\n",
            "    self.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 635, in wait\n",
            "    self._event.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-fb70b6b227a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}