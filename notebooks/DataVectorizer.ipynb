{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataVectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue-brQOCOR4A",
        "colab_type": "text"
      },
      "source": [
        "# Notebook for the experiment of building **DeCaf** (**De**sign **C**l**a**ssi**f**ier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_wliyuuasNx",
        "colab_type": "text"
      },
      "source": [
        "## Architectural Overview/Design\n",
        "![alt text](https://raw.githubusercontent.com/alvi2496/DeCaf/master/assets/DataVectorizer.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up9iaDnZM9l",
        "colab_type": "text"
      },
      "source": [
        "## Objective\n",
        "The main objective is to vectorize the `train`, `validate`, `test` and `cross` data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A-ie768Gp-2",
        "colab_type": "code",
        "outputId": "88d4c4ff-75d6-409f-f8e7-1c5191cdd884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPpS__xQYkEl",
        "colab_type": "code",
        "outputId": "c8c7e8cd-f5ac-4a5a-90e9-77782a04cb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp36-cp36m-linux_x86_64.whl size=2385791 sha256=6baeeae68ecd0b570eca76073dc5c3f905ace5eadb394c46ff1c07fb7b09eecc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEE_05oRYIKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "so_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/pre_trained/so.bin\"\n",
        "we_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/we.bin\"\n",
        "enhanced_we_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/enhanced_we_300d.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aoSOTweYRCh",
        "colab_type": "code",
        "outputId": "2ba43a7d-b38c-4577-f550-2e398bf1d1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import warnings\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "import fasttext as ft\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "# so_model = KeyedVectors.load_word2vec_format(so_model_file, binary=True)\n",
        "we_model = ft.load_model(enhanced_we_model_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND34XuJDLy2F",
        "colab_type": "text"
      },
      "source": [
        "## Read and process **TRAIN** data\n",
        "- We use three types of data from training the model. We scraped question, answer and comment data from Stack Overflow and tagged them `design` or `general`. The tagging was done automatically based on the original tag of the question. Then we process our data as we did before for our word embedding data to clear noise. We also did some additional processing to our train data. We only took those documents that contains more than 10 words. For the others, we discarded them. After processing, we got 1,00,000 documents(50,000-design, 50,000-general) for `questions.csv`, 40,000 documents(20,000-design, 20,000-general) for `answers.csv` and 60,000 documents(30,000-design, 30,000-general) for `comments.csv`.\n",
        "\n",
        "- Our train data is completely noise free, stopwords free and long documents of more than 10 words per document. All the data is randomly distributed.\n",
        "\n",
        "- After processing the data and converting the data in vector with the help of our trained word embedding model, we save the data as .npy file for quick access."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E30pMihMDCA",
        "colab_type": "text"
      },
      "source": [
        "#### Assign train data location\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGy3g1XTOC2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_question_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/questions.csv\"\n",
        "train_answer_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/answers.csv\"\n",
        "train_comment_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/comments.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjduBEkLOjcN",
        "colab_type": "text"
      },
      "source": [
        "#### Read the data with pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw_-kkRROo5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "import pandas as pd\n",
        "\n",
        "train_question = pd.read_csv(train_question_file)\n",
        "train_answer = pd.read_csv(train_answer_file)\n",
        "train_comment = pd.read_csv(train_comment_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NazCrfAzPD0J",
        "colab_type": "text"
      },
      "source": [
        "#### Explore the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbwPwlRvT2oJ",
        "colab_type": "code",
        "outputId": "800de068-ab6e-4f43-ccee-5a7a37e9946b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "print(\"Question train data\")\n",
        "print(train_question.head())\n",
        "print(\"Answer train data\")\n",
        "print(train_answer.head())\n",
        "print(\"Comment train data\")\n",
        "print(train_comment.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question train data\n",
            "                                                text    label\n",
            "0  control controls usercontrol contol controll p...   design\n",
            "1  messenger messanger messengers gtalk kik whats...  general\n",
            "2  error errors exception warning errror erorr er...   design\n",
            "3  data datas values dataset database records inf...   design\n",
            "4  start starting starts begin stop begins beginn...  general\n",
            "Answer train data\n",
            "                                                text    label\n",
            "0  just simply actually however also either since...  general\n",
            "1  does actually fact since therefore just indeed...  general\n",
            "2  following follows follwing folowing bellow fol...  general\n",
            "3  looks sounds seems feels sounded acts smells s...  general\n",
            "4  think guess probably believe maybe obviously s...   design\n",
            "Comment train data\n",
            "                                                text    label\n",
            "0  public private protected pubic pulic publicly ...   design\n",
            "1  using use uses used via utilizing supports aka...  general\n",
            "2  defined declared defines define defining redef...  general\n",
            "3  nice neat cool nifty sexy great fantastic awes...   design\n",
            "4  really truly anyway particularly probably espe...   design\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZR0EwyIPOvU",
        "colab_type": "code",
        "outputId": "c159b977-1f3e-4a99-f550-675d12b0c8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Dataset Name\", \"Shape\", \"# of design data\", \"# of general data\"]\n",
        "\n",
        "qd = train_question[train_question['label']=='design']\n",
        "qg = train_question[train_question['label']=='general']\n",
        "\n",
        "ad = train_answer[train_answer['label']=='design']\n",
        "ag = train_answer[train_answer['label']=='general']\n",
        "\n",
        "cd = train_comment[train_comment['label']=='design']\n",
        "cg = train_comment[train_comment['label']=='general']\n",
        "\n",
        "table.add_row([\"Question\", train_question.shape, qd.shape[0], qg.shape[0]])\n",
        "table.add_row([\"Answer\", train_answer.shape, ad.shape[0], ag.shape[0]])\n",
        "table.add_row([\"Comment\", train_comment.shape, cd.shape[0], cg.shape[0]])\n",
        "\n",
        "\n",
        "print(table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------------+------------------+-------------------+\n",
            "| Dataset Name |    Shape    | # of design data | # of general data |\n",
            "+--------------+-------------+------------------+-------------------+\n",
            "|   Question   | (100000, 2) |      50000       |       50000       |\n",
            "|    Answer    |  (40000, 2) |      20000       |       20000       |\n",
            "|   Comment    |  (60000, 2) |      30000       |       30000       |\n",
            "+--------------+-------------+------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ntcn6aKPE3",
        "colab_type": "text"
      },
      "source": [
        "### Convert sentences in vector uisng Word Embedding model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q52NSKvjeoQA",
        "colab_type": "text"
      },
      "source": [
        "Now we turn our head towards converting our train data to vectors of 300 dimension. We are naming our variable by the following convension:\n",
        "- question data = X_Q, question label = Y_Q\n",
        "- answer data = X_A, answer label = Y_A\n",
        "- comment data = X_C, comment label = Y_C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TmaOl6StWKM",
        "colab_type": "text"
      },
      "source": [
        "#### Location to save/retrive data in vector format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz5I9xV8tkEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Q_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/X_Q.npy\"\n",
        "Y_Q_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/Y_Q.npy\"\n",
        "\n",
        "X_A_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/X_A.npy\"\n",
        "Y_A_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/Y_A.npy\"\n",
        "\n",
        "X_C_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/X_C.npy\"\n",
        "Y_C_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/so_injected/Y_C.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q47D7-6yVIr",
        "colab_type": "text"
      },
      "source": [
        "We define `get_text_vector(data, url)` function to convert text sentences into 300 dimension word vector. We define `get_label_vector(label, url)` to convert the labels into vector.\n",
        "- look for the .npy file in the disk. if found then load the data into memory.\n",
        "- if not found then \n",
        "  - convert the text and labels into vector\n",
        "  - save the text and labels as .npy file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDBnIkvafAV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_text_vector(data, data_url):\n",
        "  if os.path.exists(data_url):\n",
        "    X = np.load(data_url)\n",
        "  else:\n",
        "    X = []\n",
        "    for sentence in data:\n",
        "      X.append(we_model.get_sentence_vector(sentence))\n",
        "    X = np.array(X)\n",
        "    np.save(data_url, X)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpb4wbAJgYrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label_vector(labels, label_url):\n",
        "  if os.path.exists(label_url):\n",
        "    Y = np.load(label_url)\n",
        "  else:\n",
        "    Y = []\n",
        "    for label in labels:\n",
        "      if label == 'design' or label == 1:\n",
        "        Y.append(1)\n",
        "      else:\n",
        "        Y.append(0)\n",
        "    Y = np.array(Y)\n",
        "    np.save(label_url, Y)\n",
        "  return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-7wCNmayK9i",
        "colab_type": "text"
      },
      "source": [
        "#### Load and inspect the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lo1ihPqbyCk",
        "colab_type": "code",
        "outputId": "56d9b70a-0688-4c04-cb31-73ec53546d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_Q = get_text_vector(train_question['text'], X_Q_url)\n",
        "Y_Q = get_label_vector(train_question['label'], Y_Q_url)\n",
        "print('Shape of X_Q: ', X_Q.shape)\n",
        "print('Shape of Y_Q: ', Y_Q.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_Q:  (100000, 300)\n",
            "Shape of Y_Q:  (100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NjL4tUcdb8z",
        "colab_type": "code",
        "outputId": "ae5111ec-d808-466d-d8b8-302ed01ee513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_A = get_text_vector(train_answer['text'], X_A_url)\n",
        "Y_A = get_label_vector(train_answer['label'], Y_A_url)\n",
        "print('Shape of X_A: ', X_A.shape)\n",
        "print('Shape of Y_A: ', Y_A.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_A:  (40000, 300)\n",
            "Shape of Y_A:  (40000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2-zNJMnspD0",
        "colab_type": "code",
        "outputId": "a78118ac-39f6-4bd5-d4eb-d13533866920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_C = get_text_vector(train_comment['text'], X_C_url)\n",
        "Y_C = get_label_vector(train_comment['label'], Y_C_url)\n",
        "print('Shape of X_C: ', X_C.shape)\n",
        "print('Shape of Y_C: ', Y_C.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_C:  (60000, 300)\n",
            "Shape of Y_C:  (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdvw7gNIVSEf",
        "colab_type": "text"
      },
      "source": [
        "## Read and process **VALIDATION** data\n",
        "- We are taking the same approach as above to read, process, convert and save our validation data.\n",
        "- Validation data contains a mixture of `question`, `answer` and `comment` data\n",
        "- X_V for the vector of the text, Y_V is the vector of the labels for validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNeKSdPtV9Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/validation_data/validation.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y0abI0aWMCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = pd.read_csv(validation_data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l240dbRLWXGe",
        "colab_type": "code",
        "outputId": "dac05005-c4d9-473d-8963-52ccceccca2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"Shape: \", validation_data.shape)\n",
        "print(validation_data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (30000, 2)\n",
            "                                                text    label\n",
            "0  better handling type issue sort development us...  general\n",
            "1  custom route dependency injection route define...   design\n",
            "2  crawler design calling async calling service l...   design\n",
            "3  page seems freeze triggered event issue based ...  general\n",
            "4  install package composer require trying compos...  general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuZkcU_aWn5t",
        "colab_type": "code",
        "outputId": "47d94150-8f14-4e23-937e-5b4e5c11ceb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Number of design data: \", validation_data[validation_data[\"label\"] == \"design\"].shape[0])\n",
        "print(\"number of general data: \", validation_data[validation_data[\"label\"] == \"general\"].shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of design data:  15000\n",
            "number of general data:  15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmQ45P1QXOnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_V = get_text_vector(validation_data['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/validation_data/X_V.npy\")\n",
        "Y_V = get_label_vector(validation_data['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/validation_data/Y_V.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grhes7JkX2ql",
        "colab_type": "code",
        "outputId": "0662fc68-158b-4e62-c076-44960e6493d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Shape of X_V: \", X_V.shape)\n",
        "print(\"Shape of Y_V: \", Y_V.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_V:  (30000, 200)\n",
            "Shape of Y_V:  (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv7WbsJpkquT",
        "colab_type": "text"
      },
      "source": [
        "## Read and process **TEST** data\n",
        "- We are taking the same approach as above to read, process, convert and save our validation data.\n",
        "- Test data contains a mixture of `question`, `answer` and `comment` data\n",
        "- X_T for the vector of the text, Y_T is the vector of the labels for validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "293UpZ0SkzhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/so_injected/test_so_injected.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qddbU7FHk9MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(test_data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuJEcM1DlFVH",
        "colab_type": "code",
        "outputId": "7f04b5d7-ffe0-47b0-b362-006855da33e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"Shape: \", test_data.shape)\n",
        "print(test_data.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (30000, 2)\n",
            "                                                text    label\n",
            "0  form forms page textbox submit webform field f...  general\n",
            "1  using use uses used via utilizing supports aka...   design\n",
            "2  scale scales scaling scaled rescale re-scale r...   design\n",
            "3  decouple de-couple decouples decoupled decoupl...   design\n",
            "4  method methods function constructor methos -me...  general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S-jB0F9lNaW",
        "colab_type": "code",
        "outputId": "fc3ffd9d-ebe1-4b59-9134-7f93144a14a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Number of design data: \", test_data[test_data[\"label\"] == \"design\"].shape[0])\n",
        "print(\"number of general data: \", test_data[test_data[\"label\"] == \"general\"].shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of design data:  15000\n",
            "number of general data:  15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHrhJIDolUO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_T = get_text_vector(test_data['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/so_injected/X_T.npy\")\n",
        "Y_T = get_label_vector(test_data['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/so_injected/Y_T.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y4OAmiklsIM",
        "colab_type": "code",
        "outputId": "9b684ceb-4468-4e7a-d7f3-731058ba4cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Shape of X_T: \", X_T.shape)\n",
        "print(\"Shape of Y_T: \", Y_T.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_T:  (30000, 300)\n",
            "Shape of Y_T:  (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2A7OJrL2W76x"
      },
      "source": [
        "## Read and process **Cross** data\n",
        "- We are taking the same approach as above to read, process, convert and save our validation data.\n",
        "- Test data contains a mixture of `question`, `answer` and `comment` data\n",
        "- X_T for the vector of the text, Y_T is the vector of the labels for validation data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLgkZcAxXMRt",
        "colab_type": "text"
      },
      "source": [
        "### Cross dataset \n",
        "We are taking the following datasets to validate the models:\n",
        "- Brunet 2014 (brunet2014.csv)\n",
        "- Shakiba 2016 (shakiba2016.csv)\n",
        "- Viviani 2018 (viviani2018.csv)\n",
        "- Self Admitted Technical Debt/ SATD (satd.csv)\n",
        "- Stack Overflow (so.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lS6U7gEiW7SN",
        "colab": {}
      },
      "source": [
        "cross_dataset_names = [\n",
        "                       \"Brunet 2014\", \n",
        "                       \"Shakiba 2016\", \"Viviani 2018\",\n",
        "                       \"SATD\"\n",
        "]\n",
        "\n",
        "brunet2014 = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/brunet2014.csv\")\n",
        "shakiba2016 = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/shakiba2016.csv\")\n",
        "viviani2018 = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/viviani2018.csv\")\n",
        "satd = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/satd.csv\")\n",
        "# so = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/so.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZjP7efZPW7EE"
      },
      "source": [
        "### Examine the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g1AZ_jD8WOit",
        "outputId": "aca3a98b-ee1a-48e4-ca48-66b475677531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Dataset Name\", \"Total # of rows\", \"# of design\", \"# of general\"]\n",
        "table.add_row([\"Brunet 2014\", brunet2014.shape[0], \\\n",
        "               brunet2014[brunet2014['label'] == 1].shape[0], \\\n",
        "               brunet2014[brunet2014['label'] == 0].shape[0]])\n",
        "table.add_row([\"Shakiba 2016\", shakiba2016.shape[0], \\\n",
        "               shakiba2016[shakiba2016['label'] == 1].shape[0], \\\n",
        "               shakiba2016[shakiba2016['label'] == 0 ].shape[0]])\n",
        "table.add_row([\"Viviani 2018\", viviani2018.shape[0], \\\n",
        "               viviani2018[viviani2018['label'] == 1].shape[0], \\\n",
        "               viviani2018[viviani2018['label'] == 0 ].shape[0]])\n",
        "table.add_row([\"SATD\", satd.shape[0], \\\n",
        "               satd[satd['label'] == 1].shape[0], \\\n",
        "               satd[satd['label'] == 0 ].shape[0]])\n",
        "# table.add_row([\"Stack overflow\", so.shape[0], \\\n",
        "#                so[so['label'] == 1].shape[0], \\\n",
        "#                so[so['label'] == 0 ].shape[0]])\n",
        "print(table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----------------+-------------+--------------+\n",
            "| Dataset Name | Total # of rows | # of design | # of general |\n",
            "+--------------+-----------------+-------------+--------------+\n",
            "| Brunet 2014  |       159       |      61     |      98      |\n",
            "| Shakiba 2016 |        67       |      25     |      42      |\n",
            "| Viviani 2018 |       1969      |     1007    |     962      |\n",
            "|     SATD     |       2609      |     558     |     2051     |\n",
            "+--------------+-----------------+-------------+--------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HoqRXqYkWOYX"
      },
      "source": [
        "### Vectorize and Save the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xzllpbpiWOOf",
        "outputId": "913c3caa-f8a6-45ad-b498-9869dec50878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_brunet2014 = get_text_vector(brunet2014['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_brunet2014.npy\")\n",
        "Y_brunet2014 = get_label_vector(brunet2014['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_brunet2014.npy\")\n",
        "print(X_brunet2014.shape)\n",
        "print(Y_brunet2014.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159, 300)\n",
            "(159,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b37T88vpWOEH",
        "outputId": "43b2c11f-dafa-4de2-c1c3-be4181d38957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_shakiba2016 = get_text_vector(shakiba2016['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_shakiba2016.npy\")\n",
        "Y_shakiba2016 = get_label_vector(shakiba2016['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_shakiba2016.npy\")\n",
        "print(X_shakiba2016.shape)\n",
        "print(Y_shakiba2016.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67, 300)\n",
            "(67,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "soQU0FwiWN5W",
        "outputId": "3c10051d-ad18-40ec-de79-24242bcbdfdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_viviani2018 = get_text_vector(viviani2018['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_viviani2018.npy\")\n",
        "Y_viviani2018 = get_label_vector(viviani2018['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_viviani2018.npy\")\n",
        "print(X_viviani2018.shape)\n",
        "print(Y_viviani2018.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1969, 300)\n",
            "(1969,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fQup0xUMWNrH",
        "outputId": "7459eba6-fe80-4ca0-9201-cc6c9a6b1649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_satd = get_text_vector(satd['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/X_satd.npy\")\n",
        "Y_satd = get_label_vector(satd['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/so_vocab_injected/Y_satd.npy\")\n",
        "print(X_satd.shape)\n",
        "print(Y_satd.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2609, 300)\n",
            "(2609,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pdFS1HudWNcg",
        "colab": {}
      },
      "source": [
        "# X_so = get_text_vector(so['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/X_so.npy\")\n",
        "# Y_so = get_label_vector(so['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/Y_so.npy\")\n",
        "# print(X_so.shape)\n",
        "# print(Y_so.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}