{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataVectorizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue-brQOCOR4A",
        "colab_type": "text"
      },
      "source": [
        "# Notebook for the experiment of building **DeCaf** (**De**sign **C**l**a**ssi**f**ier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_wliyuuasNx",
        "colab_type": "text"
      },
      "source": [
        "## Architectural Overview/Design\n",
        "![alt text](https://raw.githubusercontent.com/alvi2496/DeCaf/master/assets/DataVectorizer.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up9iaDnZM9l",
        "colab_type": "text"
      },
      "source": [
        "## Objective\n",
        "The main objective is to vectorize the `train`, `validate`, `test` and `cross` data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A-ie768Gp-2",
        "colab_type": "code",
        "outputId": "0ff02b85-cf19-4811-be72-b03260942c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPpS__xQYkEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ca986158-50a0-4f88-9854-f7afa53be020"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.0.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEE_05oRYIKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "so_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/pre_trained/so.bin\"\n",
        "we_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/we.bin\"\n",
        "enhanced_we_model_file = \"/content/drive/My Drive/documents/projects/DeCaf/models/enhanced_we.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aoSOTweYRCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85428432-859a-4d6a-d54f-3f1061aaa487"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import warnings\n",
        "import os\n",
        "from datetime import datetime as dt\n",
        "import fasttext as ft\n",
        "\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "so_model = KeyedVectors.load_word2vec_format(so_model_file, binary=True)\n",
        "we_model = ft.load_model(we_model_file)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND34XuJDLy2F",
        "colab_type": "text"
      },
      "source": [
        "## Read and process **TRAIN** data\n",
        "- We use three types of data from training the model. We scraped question, answer and comment data from Stack Overflow and tagged them `design` or `general`. The tagging was done automatically based on the original tag of the question. Then we process our data as we did before for our word embedding data to clear noise. We also did some additional processing to our train data. We only took those documents that contains more than 10 words. For the others, we discarded them. After processing, we got 1,00,000 documents(50,000-design, 50,000-general) for `questions.csv`, 40,000 documents(20,000-design, 20,000-general) for `answers.csv` and 60,000 documents(30,000-design, 30,000-general) for `comments.csv`.\n",
        "\n",
        "- Our train data is completely noise free, stopwords free and long documents of more than 10 words per document. All the data is randomly distributed.\n",
        "\n",
        "- After processing the data and converting the data in vector with the help of our trained word embedding model, we save the data as .npy file for quick access."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E30pMihMDCA",
        "colab_type": "text"
      },
      "source": [
        "#### Assign train data location\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGy3g1XTOC2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_question_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/questions.csv\"\n",
        "train_answer_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/answers.csv\"\n",
        "train_comment_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/comments.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjduBEkLOjcN",
        "colab_type": "text"
      },
      "source": [
        "#### Read the data with pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw_-kkRROo5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "import pandas as pd\n",
        "\n",
        "train_question = pd.read_csv(train_question_file)\n",
        "train_answer = pd.read_csv(train_answer_file)\n",
        "train_comment = pd.read_csv(train_comment_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NazCrfAzPD0J",
        "colab_type": "text"
      },
      "source": [
        "#### Explore the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbwPwlRvT2oJ",
        "colab_type": "code",
        "outputId": "fd390909-3274-4cb8-892f-4a68dad204ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "print(\"Question train data\")\n",
        "print(train_question.head())\n",
        "print(\"Answer train data\")\n",
        "print(train_answer.head())\n",
        "print(\"Comment train data\")\n",
        "print(train_comment.head())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question train data\n",
            "                                            question    label\n",
            "0  control pattern according principle elsewhere ...   design\n",
            "1  messenger throws error getting errors messenge...  general\n",
            "2  error cannot find symbol variable trying integ...   design\n",
            "3  data mapper pattern different repository patte...   design\n",
            "4  start project using poetry start project using...  general\n",
            "Answer train data\n",
            "                                              answer    label\n",
            "0  just tell solved issue found feed posted file ...  general\n",
            "1  does actually implement copy cannot implement ...  general\n",
            "2  following comments included code note will spe...  general\n",
            "3  looks user present undefined method error need...  general\n",
            "4  think better natural argue method names explic...   design\n",
            "Comment train data\n",
            "                                             comment    label\n",
            "0  public declared class later library members sa...   design\n",
            "1  using server definitely needs reasonable chanc...  general\n",
            "2  defined crossproduct read rust programming lan...  general\n",
            "3  nice just clear means calling route times data...   design\n",
            "4  really difficult understand requirements examp...   design\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZR0EwyIPOvU",
        "colab_type": "code",
        "outputId": "ddaf5143-0c50-4932-f308-d2f71db3b5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Dataset Name\", \"Shape\", \"# of design data\", \"# of general data\"]\n",
        "\n",
        "qd = train_question[train_question['label']=='design']\n",
        "qg = train_question[train_question['label']=='general']\n",
        "\n",
        "ad = train_answer[train_answer['label']=='design']\n",
        "ag = train_answer[train_answer['label']=='general']\n",
        "\n",
        "cd = train_comment[train_comment['label']=='design']\n",
        "cg = train_comment[train_comment['label']=='general']\n",
        "\n",
        "table.add_row([\"Question\", train_question.shape, qd.shape[0], qg.shape[0]])\n",
        "table.add_row([\"Answer\", train_answer.shape, ad.shape[0], ag.shape[0]])\n",
        "table.add_row([\"Comment\", train_comment.shape, cd.shape[0], cg.shape[0]])\n",
        "\n",
        "\n",
        "print(table)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------------+------------------+-------------------+\n",
            "| Dataset Name |    Shape    | # of design data | # of general data |\n",
            "+--------------+-------------+------------------+-------------------+\n",
            "|   Question   | (100000, 2) |      50000       |       50000       |\n",
            "|    Answer    |  (40000, 2) |      20000       |       20000       |\n",
            "|   Comment    |  (60000, 2) |      30000       |       30000       |\n",
            "+--------------+-------------+------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4ntcn6aKPE3",
        "colab_type": "text"
      },
      "source": [
        "### Convert sentences in vector uisng Word Embedding model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q52NSKvjeoQA",
        "colab_type": "text"
      },
      "source": [
        "Now we turn our head towards converting our train data to vectors of 300 dimension. We are naming our variable by the following convension:\n",
        "- question data = X_Q, question label = Y_Q\n",
        "- answer data = X_A, answer label = Y_A\n",
        "- comment data = X_C, comment label = Y_C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TmaOl6StWKM",
        "colab_type": "text"
      },
      "source": [
        "#### Location to save/retrive data in vector format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz5I9xV8tkEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Q_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/X_Q.npy\"\n",
        "Y_Q_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/Y_Q.npy\"\n",
        "\n",
        "X_A_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/X_A.npy\"\n",
        "Y_A_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/Y_A.npy\"\n",
        "\n",
        "X_C_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/X_C.npy\"\n",
        "Y_C_url = \"/content/drive/My Drive/documents/projects/DeCaf/data/train_data/Y_C.npy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q47D7-6yVIr",
        "colab_type": "text"
      },
      "source": [
        "We define `get_text_vector(data, url)` function to convert text sentences into 300 dimension word vector. We define `get_label_vector(label, url)` to convert the labels into vector.\n",
        "- look for the .npy file in the disk. if found then load the data into memory.\n",
        "- if not found then \n",
        "  - convert the text and labels into vector\n",
        "  - save the text and labels as .npy file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDBnIkvafAV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_text_vector(data, data_url):\n",
        "  if os.path.exists(data_url):\n",
        "    X = np.load(data_url)\n",
        "  else:\n",
        "    X = []\n",
        "    for sentence in data:\n",
        "      X.append(we_model.get_sentence_vector(sentence))\n",
        "    X = np.array(X)\n",
        "    np.save(data_url, X)\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpb4wbAJgYrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label_vector(labels, label_url):\n",
        "  if os.path.exists(label_url):\n",
        "    Y = np.load(label_url)\n",
        "  else:\n",
        "    Y = []\n",
        "    for label in labels:\n",
        "      if label == 'design' or label == 1:\n",
        "        Y.append(1)\n",
        "      else:\n",
        "        Y.append(0)\n",
        "    Y = np.array(Y)\n",
        "    np.save(label_url, Y)\n",
        "  return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-7wCNmayK9i",
        "colab_type": "text"
      },
      "source": [
        "#### Load and inspect the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lo1ihPqbyCk",
        "colab_type": "code",
        "outputId": "a340bf7d-94c1-4638-fc94-1d0a65a81605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_Q = get_text_vector(train_question['question'], X_Q_url)\n",
        "Y_Q = get_label_vector(train_question['label'], Y_Q_url)\n",
        "print('Shape of X_Q: ', X_Q.shape)\n",
        "print('Shape of Y_Q: ', Y_Q.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_Q:  (100000, 300)\n",
            "Shape of Y_Q:  (100000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NjL4tUcdb8z",
        "colab_type": "code",
        "outputId": "f9b035d9-6294-49a1-d77f-7fe46a22ec0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_A = get_text_vector(train_answer['answer'], X_A_url)\n",
        "Y_A = get_label_vector(train_answer['label'], Y_A_url)\n",
        "print('Shape of X_A: ', X_A.shape)\n",
        "print('Shape of Y_A: ', Y_A.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_A:  (40000, 300)\n",
            "Shape of Y_A:  (40000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2-zNJMnspD0",
        "colab_type": "code",
        "outputId": "cda27252-8e26-4dac-aca2-e4258808db44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_C = get_text_vector(train_comment['comment'], X_C_url)\n",
        "Y_C = get_label_vector(train_comment['label'], Y_C_url)\n",
        "print('Shape of X_C: ', X_C.shape)\n",
        "print('Shape of Y_C: ', Y_C.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_C:  (60000, 300)\n",
            "Shape of Y_C:  (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdvw7gNIVSEf",
        "colab_type": "text"
      },
      "source": [
        "## Read and process **VALIDATION** data\n",
        "- We are taking the same approach as above to read, process, convert and save our validation data.\n",
        "- Validation data contains a mixture of `question`, `answer` and `comment` data\n",
        "- X_V for the vector of the text, Y_V is the vector of the labels for validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNeKSdPtV9Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/validation_data/validation.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y0abI0aWMCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data = pd.read_csv(validation_data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l240dbRLWXGe",
        "colab_type": "code",
        "outputId": "a1b6ed9d-e6d4-43b0-8fa9-8c925722930b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"Shape: \", validation_data.shape)\n",
        "print(validation_data.head())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (30000, 2)\n",
            "                                                text    label\n",
            "0  better handling type issue sort development us...  general\n",
            "1  custom route dependency injection route define...   design\n",
            "2  crawler design calling async calling service l...   design\n",
            "3  page seems freeze triggered event issue based ...  general\n",
            "4  install package composer require trying compos...  general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuZkcU_aWn5t",
        "colab_type": "code",
        "outputId": "a4d0e112-3adf-4cf4-fe02-8e7317798df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Number of design data: \", validation_data[validation_data[\"label\"] == \"design\"].shape[0])\n",
        "print(\"number of general data: \", validation_data[validation_data[\"label\"] == \"general\"].shape[0])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of design data:  15000\n",
            "number of general data:  15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmQ45P1QXOnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_V = get_text_vector(validation_data['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/validation_data/X_V.npy\")\n",
        "Y_V = get_label_vector(validation_data['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/validation_data/Y_V.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grhes7JkX2ql",
        "colab_type": "code",
        "outputId": "b45005d4-804c-4027-e040-62535c8a1edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Shape of X_V: \", X_V.shape)\n",
        "print(\"Shape of Y_V: \", Y_V.shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_V:  (30000, 300)\n",
            "Shape of Y_V:  (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv7WbsJpkquT",
        "colab_type": "text"
      },
      "source": [
        "## Read and process **TEST** data\n",
        "- We are taking the same approach as above to read, process, convert and save our validation data.\n",
        "- Test data contains a mixture of `question`, `answer` and `comment` data\n",
        "- X_T for the vector of the text, Y_T is the vector of the labels for validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "293UpZ0SkzhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_file = \"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/test.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qddbU7FHk9MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = pd.read_csv(test_data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuJEcM1DlFVH",
        "colab_type": "code",
        "outputId": "8a144ba4-c83e-4c20-c28f-c5c99f948dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(\"Shape: \", test_data.shape)\n",
        "print(test_data.head())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (30000, 2)\n",
            "                                                text    label\n",
            "0  form using submit insert fairly working stuck ...  general\n",
            "1  using shared drive portal storage sharing clie...   design\n",
            "2  scale parallel project looking using together ...   design\n",
            "3  decouple service associated database separate ...   design\n",
            "4  method does exist trying send mail user know s...  general\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S-jB0F9lNaW",
        "colab_type": "code",
        "outputId": "1ebdc0db-664f-4db0-dad9-336f0b1773f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Number of design data: \", test_data[test_data[\"label\"] == \"design\"].shape[0])\n",
        "print(\"number of general data: \", test_data[test_data[\"label\"] == \"general\"].shape[0])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of design data:  15000\n",
            "number of general data:  15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHrhJIDolUO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_T = get_text_vector(test_data['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/X_T.npy\")\n",
        "Y_T = get_label_vector(test_data['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/test_data/Y_T.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y4OAmiklsIM",
        "colab_type": "code",
        "outputId": "7e12592e-2181-4f66-bcfe-b8b75b513bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Shape of X_T: \", X_T.shape)\n",
        "print(\"Shape of Y_T: \", Y_T.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_T:  (30000, 300)\n",
            "Shape of Y_T:  (30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2A7OJrL2W76x"
      },
      "source": [
        "## Read and process **Cross** data\n",
        "- We are taking the same approach as above to read, process, convert and save our validation data.\n",
        "- Test data contains a mixture of `question`, `answer` and `comment` data\n",
        "- X_T for the vector of the text, Y_T is the vector of the labels for validation data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLgkZcAxXMRt",
        "colab_type": "text"
      },
      "source": [
        "### Cross dataset \n",
        "We are taking the following datasets to validate the models:\n",
        "- Brunet 2014 (brunet2014.csv)\n",
        "- Shakiba 2016 (shakiba2016.csv)\n",
        "- Viviani 2018 (viviani2018.csv)\n",
        "- Self Admitted Technical Debt/ SATD (satd.csv)\n",
        "- Stack Overflow (so.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lS6U7gEiW7SN",
        "colab": {}
      },
      "source": [
        "cross_dataset_names = [\n",
        "                       \"Brunet 2014\", \n",
        "                       \"Shakiba 2016\", \"Viviani 2018\",\n",
        "                       \"SATD\"\n",
        "]\n",
        "\n",
        "brunet2014 = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/brunet2014.csv\")\n",
        "shakiba2016 = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/shakiba2016.csv\")\n",
        "viviani2018 = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/viviani2018.csv\")\n",
        "satd = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/satd.csv\")\n",
        "so = pd.read_csv(\"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/so.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZjP7efZPW7EE"
      },
      "source": [
        "### Examine the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "37c1eeab-ea3a-410a-886b-ce9e02fb29ad",
        "id": "g1AZ_jD8WOit",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Dataset Name\", \"Total # of rows\", \"# of design\", \"# of general\"]\n",
        "table.add_row([\"Brunet 2014\", brunet2014.shape[0], \\\n",
        "               brunet2014[brunet2014['label'] == 1].shape[0], \\\n",
        "               brunet2014[brunet2014['label'] == 0].shape[0]])\n",
        "table.add_row([\"Shakiba 2016\", shakiba2016.shape[0], \\\n",
        "               shakiba2016[shakiba2016['label'] == 1].shape[0], \\\n",
        "               shakiba2016[shakiba2016['label'] == 0 ].shape[0]])\n",
        "table.add_row([\"Viviani 2018\", viviani2018.shape[0], \\\n",
        "               viviani2018[viviani2018['label'] == 1].shape[0], \\\n",
        "               viviani2018[viviani2018['label'] == 0 ].shape[0]])\n",
        "table.add_row([\"SATD\", satd.shape[0], \\\n",
        "               satd[satd['label'] == 1].shape[0], \\\n",
        "               satd[satd['label'] == 0 ].shape[0]])\n",
        "table.add_row([\"Stack overflow\", so.shape[0], \\\n",
        "               so[so['label'] == 1].shape[0], \\\n",
        "               so[so['label'] == 0 ].shape[0]])\n",
        "print(table)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-----------------+-------------+--------------+\n",
            "|  Dataset Name  | Total # of rows | # of design | # of general |\n",
            "+----------------+-----------------+-------------+--------------+\n",
            "|  Brunet 2014   |       159       |      61     |      98      |\n",
            "|  Shakiba 2016  |        67       |      25     |      42      |\n",
            "|  Viviani 2018  |       159       |      61     |      98      |\n",
            "|      SATD      |       2609      |     558     |     2051     |\n",
            "| Stack overflow |      46744      |    23879    |    22865     |\n",
            "+----------------+-----------------+-------------+--------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HoqRXqYkWOYX"
      },
      "source": [
        "### Vectorize and Save the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a37583e0-a2ee-40e4-89c9-541da80dbbae",
        "id": "xzllpbpiWOOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X_brunet2014 = get_text_vector(brunet2014['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/X_brunet2014.npy\")\n",
        "Y_brunet2014 = get_label_vector(brunet2014['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/Y_brunet2014.npy\")\n",
        "print(X_brunet2014.shape)\n",
        "print(Y_brunet2014.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159, 300)\n",
            "(159,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b37T88vpWOEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "deec6efa-4b2c-4952-a905-db02e03bf8e6"
      },
      "source": [
        "X_shakiba2016 = get_text_vector(shakiba2016['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/X_shakiba2016.npy\")\n",
        "Y_shakiba2016 = get_label_vector(shakiba2016['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/Y_shakiba2016.npy\")\n",
        "print(X_shakiba2016.shape)\n",
        "print(Y_shakiba2016.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67, 300)\n",
            "(67,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "soQU0FwiWN5W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1b8c6d02-9d03-44f0-c0bf-5ce30713e9cc"
      },
      "source": [
        "X_viviani2018 = get_text_vector(viviani2018['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/X_viviani2018.npy\")\n",
        "Y_viviani2018 = get_label_vector(viviani2018['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/Y_viviani2018.npy\")\n",
        "print(X_viviani2018.shape)\n",
        "print(Y_viviani2018.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159, 300)\n",
            "(159,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fQup0xUMWNrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d81773a3-5051-44e1-e353-a4b1b8237dba"
      },
      "source": [
        "X_satd = get_text_vector(satd['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/X_satd.npy\")\n",
        "Y_satd = get_label_vector(satd['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/Y_satd.npy\")\n",
        "print(X_satd.shape)\n",
        "print(Y_satd.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2609, 300)\n",
            "(2609,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pdFS1HudWNcg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d2275aaa-c5de-48da-a75e-2ca3ccafa8e0"
      },
      "source": [
        "X_so = get_text_vector(so['text'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/X_so.npy\")\n",
        "Y_so = get_label_vector(so['label'], \"/content/drive/My Drive/documents/projects/DeCaf/data/cross_data/processed/Y_so.npy\")\n",
        "print(X_so.shape)\n",
        "print(Y_so.shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(46744, 300)\n",
            "(46744,)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}