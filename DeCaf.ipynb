{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeCaf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1EUgzrK_eyYQN2DgTaBk87JxbraIDfNNx",
      "authorship_tag": "ABX9TyOh3lnIBVRBNf/3alk5ubT2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue-brQOCOR4A",
        "colab_type": "text"
      },
      "source": [
        "## Notebook for the experiment of building **DeCaf** (**De**sign **C**l**a**ssi**f**ier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Up9iaDnZM9l",
        "colab_type": "text"
      },
      "source": [
        "### Objective\n",
        "The main objective is to classify discussions from pull request, issue tracker commit messages and code comments as `design` or `general`. We also want to make the classifier cross project compatible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Av-qUhZOah",
        "colab_type": "text"
      },
      "source": [
        "### Data Collection\n",
        "- We intent to have three types of data. One data is to train the `Word Embedding` model. As `Word Embedding` requires structured form of literature, we have used sentences from literatures(ex. papers and books). Also we have restricted our choice of papers and books to only from the Software Engineering domain for keep the context of our `Word Embedding` model restricted to Software Engineering. Our `Word Embedding` model will be used to vectorize our train data.\n",
        "- We have collected our train data from Stack Overflow questions, answers and comments. We have collected data and classified them as `design` or `general` based on the tag. For example, questions and answers that contain `design-patterns` or `software-design` falls under the class of `design` while data tagged as `javascript` or `django` as classified as `general`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2xxEU72ZPf_",
        "colab_type": "text"
      },
      "source": [
        "### Data Cleaning\n",
        "Raw data can have a lot of noise. Specially when scraped from documents of website, it can contain a lot of misinformation in the form of names, punctuations, numbers(ex. years), misspelled and incompleted words. Also it can have a lot of stopwords that can make the model confused. We have removed all this to make our data as clean as possible. After the cleaning process, out data only contains words that are not stopwords, present in the english dictionary and has lenght greater than three."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A-ie768Gp-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOd6VG5aIqdf",
        "colab_type": "text"
      },
      "source": [
        "### Assign Data location\n",
        "- literature: holds the data for word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9gkg8dEI5fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "literature_file = \"/content/drive/My Drive/UVic-RA/DeCaf/data/literature.txt\"\n",
        "we_model_file = \"/content/drive/My Drive/UVic-RA/DeCaf/model/we.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnD4SBPUJSir",
        "colab_type": "text"
      },
      "source": [
        "### Create Word Embedding\n",
        "- Use fasttext for word embedding\n",
        "1. we take literature.txt as our input data.\n",
        "2. we train the classifier upsupervised since we just want to group the data according to the similarity.\n",
        "3. we have used skipgram as we have observe that skipgram models works better with subword information that cbow\n",
        "4. we are taking words with character number from 4-20. since we are removing every word less than three characters, its not important to take the characters less than 4 characters. Also, the design words seems to be on the bigger side. for ex. reproduceability contains 16 characters. we are considering characters upto 25 characters.\n",
        "5. We are taking 300 dimension of the words. Also looping for 10 epochs. Both because the training corpus is relatively small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8LPXDN4KJMH",
        "colab_type": "code",
        "outputId": "aec0fe77-2e29-42e8-d9d1-b77fe25974c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (45.2.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9GxG-n5SwdC",
        "colab_type": "text"
      },
      "source": [
        "### Train the `Word Embedding` model and save it as we.bin\n",
        "- Train and save the model if the model is not present\n",
        "- Load the model from disk if preselt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJm0O3_8KsMs",
        "colab_type": "code",
        "outputId": "6788e757-07f0-4c5a-929a-a518aba8e326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "from datetime import datetime as dt\n",
        "import fasttext as ft\n",
        "\n",
        "if not os.path.exists(we_model_file):\n",
        "  prints(str(dt.now())+' Training Word Embedding model...')\n",
        "  model = ft.train_unsupervised(literature_file, \"skipgram\", minn=4, maxn=25, dim=300, epoch=10)\n",
        "  model.save_model(we_model_file)\n",
        "  print(str(dt.now())+' Model trained and saved successfully')\n",
        "else:\n",
        "  print(str(dt.now())+' Loading Word Embedding model from disk...')\n",
        "  model = ft.load_model(we_model_file)\n",
        "  print(str(dt.now())+' Model loaded successfully.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-16 08:59:03.262021 Loading Word Embedding model from disk...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-16 08:59:12.913266 Model loaded successfully.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ezQOGUS9JO",
        "colab_type": "text"
      },
      "source": [
        "### Playing around with the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgToIpCwXp5F",
        "colab_type": "text"
      },
      "source": [
        "Get the dimention of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XgUwC1mXsxb",
        "colab_type": "code",
        "outputId": "2a3c5d6e-7863-41fa-f0de-af8572f9c2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.get_dimension()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGzgaNhGTFeV",
        "colab_type": "text"
      },
      "source": [
        "Get the words of the model... For a demo... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqgszQ6rXBmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_words()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfDXAMsiXizi",
        "colab_type": "text"
      },
      "source": [
        "Get the vector of a word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwQIRXXdXWJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_word_vector('Maintainability')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmzrg38PXzxt",
        "colab_type": "text"
      },
      "source": [
        "Get the vector of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otivEp_7X3I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.get_sentence_vector(\"Add performance tracker to active admin jobs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND34XuJDLy2F",
        "colab_type": "text"
      },
      "source": [
        "### Read train data\n",
        "We use three types of data from training the model. We scraped question, answer and comment data from Stack Overflow and tagged them `design` or `general`. The tagging was done automatically based on the original tag of the question. Then we process our data as we did before for our word embedding data to clear noise. We also did some additional processing to our train data. We only took those documents that contains more than 10 words. For the others, we discarded them. After processing, we got 1,00,000 documents(50,000-design, 50,000-general) for `questions.csv`, 40,000 documents(20,000-design, 20,000-general) for `answers.csv` and 60,000 documents(30,000-design, 30,000-general) for `comments.csv`.\n",
        "\n",
        "Our train data is complete noise free, stopwords free and long documents of more than 10 words per document. All the data is randomly distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E30pMihMDCA",
        "colab_type": "text"
      },
      "source": [
        "#### Assign train data location\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGy3g1XTOC2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_question_file = \"/content/drive/My Drive/UVic-RA/DeCaf/data/train_data/questions.csv\"\n",
        "train_answer_file = \"/content/drive/My Drive/UVic-RA/DeCaf/data/train_data/answers.csv\"\n",
        "train_comment_file = \"/content/drive/My Drive/UVic-RA/DeCaf/data/train_data/comments.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjduBEkLOjcN",
        "colab_type": "text"
      },
      "source": [
        "#### Read the data with pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw_-kkRROo5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "train_question = pd.read_csv(train_question_file)\n",
        "train_answer = pd.read_csv(train_answer_file)\n",
        "train_comment = pd.read_csv(train_comment_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NazCrfAzPD0J",
        "colab_type": "text"
      },
      "source": [
        "#### Explore the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbwPwlRvT2oJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b5527ecd-3435-43f3-affc-36cbff82c71b"
      },
      "source": [
        "print(\"Question train data\")\n",
        "print(train_question.head())\n",
        "print(\"Answer train data\")\n",
        "print(train_answer.head())\n",
        "print(\"Comment train data\")\n",
        "print(train_comment.head())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question train data\n",
            "                                            question    label\n",
            "0  android acknowledge status when android acknow...  general\n",
            "1  error when error when check error name uncaugh...  general\n",
            "2  quickly retrieve property info when property k...   design\n",
            "3  define good closed taking class called first l...   design\n",
            "4  rails create service class factory trying writ...  general\n",
            "Answer train data\n",
            "                                              answer    label\n",
            "0  return modified object instead attempting modi...   design\n",
            "1  think chaining popular populate request data p...   design\n",
            "2  good start kind design pattern inside grade gr...   design\n",
            "3  note referencing aware rules apply frameworks ...   design\n",
            "4  need method entity interface entity want entit...  general\n",
            "Comment train data\n",
            "                                             comment    label\n",
            "0  launch experience instruments pretty completel...  general\n",
            "1  dangerous path walk down instead letting insta...   design\n",
            "2  point write code access members themselves poi...   design\n",
            "3  better stick ever invoke public members constr...   design\n",
            "4  martin fowlers article fluent interfaces seen ...   design\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZR0EwyIPOvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6b4a4f45-13dc-420b-e5a0-9214639e9a0a"
      },
      "source": [
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Dataset Name\", \"Shape\", \"# of design data\", \"# of general data\"]\n",
        "\n",
        "qd = train_question[train_question['label']=='design']\n",
        "qg = train_question[train_question['label']=='general']\n",
        "\n",
        "ad = train_answer[train_answer['label']=='design']\n",
        "ag = train_answer[train_answer['label']=='general']\n",
        "\n",
        "cd = train_comment[train_comment['label']=='design']\n",
        "cg = train_comment[train_comment['label']=='general']\n",
        "\n",
        "table.add_row([\"Question\", train_question.shape, qd.shape[0], qg.shape[0]])\n",
        "table.add_row([\"Answer\", train_answer.shape, ad.shape[0], ag.shape[0]])\n",
        "table.add_row([\"Comment\", train_comment.shape, cd.shape[0], cg.shape[0]])\n",
        "\n",
        "\n",
        "print(table)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-------------+------------------+-------------------+\n",
            "| Dataset Name |    Shape    | # of design data | # of general data |\n",
            "+--------------+-------------+------------------+-------------------+\n",
            "|   Question   | (100000, 2) |      50000       |       50000       |\n",
            "|    Answer    |  (40000, 2) |      20000       |       20000       |\n",
            "|   Comment    |  (60000, 2) |      30000       |       30000       |\n",
            "+--------------+-------------+------------------+-------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}